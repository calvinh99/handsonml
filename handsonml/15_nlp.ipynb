{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f98ad507-9cdc-4d04-b6d1-4fa68f0d3dc2",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "348eb39c-8555-4652-8b59-6ba4107f63a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle math and data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import math\n",
    "\n",
    "# to plot nice figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# handle files\n",
    "import os\n",
    "import sys\n",
    "import joblib\n",
    "\n",
    "# hash table classes\n",
    "from collections import Counter\n",
    "\n",
    "# output\n",
    "import tqdm\n",
    "\n",
    "# deep learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f07a85-17c4-4eba-9515-37523448213b",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9870dc1-220d-4e89-a895-4c6ac23c9d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 69\n",
    "\n",
    "K = keras.backend\n",
    "\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "\n",
    "def reset_backend():\n",
    "    K.clear_session()\n",
    "    np.random.seed(SEED)\n",
    "    tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa39cc2-73d0-4e43-bab2-37484e6d9da3",
   "metadata": {},
   "source": [
    "# Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921b2a26-9c7d-4936-82d0-61efae09143f",
   "metadata": {},
   "source": [
    "## Generate Shakespearean Text With Character RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3965b13-b6d5-455f-b527-2ad74bffcd7a",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13880873-8739-4de1-9f9a-808efed0884d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://homl.info/shakespeare\n",
      "1115394/1115394 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "DOWNLOAD_URL = \"https://homl.info/shakespeare\"\n",
    "filepath = keras.utils.get_file(\"shakespeare.txt\", DOWNLOAD_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37e8d25e-7dc2-4191-b5c9-bc35f664c09f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/calvinhuang/.keras/datasets/shakespeare.txt'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d870c763-2c78-4d54-98be-7121a2961e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filepath) as f:\n",
    "    shakespeare_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a33e8ba3-878b-426c-9fd9-7808b74e1045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115394"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(shakespeare_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d273bda-dedd-4965-a7c2-fc21cfbbc224",
   "metadata": {},
   "source": [
    "Over 1 million characters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360ca349-3a73-4ded-9ab5-61c91928704b",
   "metadata": {},
   "source": [
    "Let's encode our text, basically char to indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51556d70-279a-4969-a851-3f72f1033ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(shakespeare_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235a7a63-67f5-467d-8e07-cae66e4a10bb",
   "metadata": {},
   "source": [
    "Now we can use the tokenizer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015e8864-85b2-4824-9386-016388af0f5b",
   "metadata": {},
   "source": [
    "Wrap the text in a list, because the method by default will convert each text in the given `texts`. Which means if you just pass the string, it will convert each character to its own sequence and you will have a list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "675aac52-46cf-42e2-8de1-aff7350b78c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[7, 6, 31, 1, 15, 16, 1, 10, 5, 15, 2, 1, 6, 8, 1, 19, 5, 12, 26, 6, 10, 31, 11]]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences([\"Hi! My name is Calvin!\\n\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a6d6f58e-417f-4cec-b45f-a2ff4f2a9eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['h i !   m y   n a m e   i s   c a l v i n ! \\n']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sequences_to_texts([[7, 6, 31, 1, 15, 16, 1, 10, 5, 15, 2, 1, 6, 8, 1, 19, 5, 12, 26, 6, 10, 31, 11]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "27008d75-cba8-4cb4-aa60-78fcbf320066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 1,\n",
       " 'e': 2,\n",
       " 't': 3,\n",
       " 'o': 4,\n",
       " 'a': 5,\n",
       " 'i': 6,\n",
       " 'h': 7,\n",
       " 's': 8,\n",
       " 'r': 9,\n",
       " 'n': 10,\n",
       " '\\n': 11,\n",
       " 'l': 12,\n",
       " 'd': 13,\n",
       " 'u': 14,\n",
       " 'm': 15,\n",
       " 'y': 16,\n",
       " 'w': 17,\n",
       " ',': 18,\n",
       " 'c': 19,\n",
       " 'f': 20,\n",
       " 'g': 21,\n",
       " 'b': 22,\n",
       " 'p': 23,\n",
       " ':': 24,\n",
       " 'k': 25,\n",
       " 'v': 26,\n",
       " '.': 27,\n",
       " \"'\": 28,\n",
       " ';': 29,\n",
       " '?': 30,\n",
       " '!': 31,\n",
       " '-': 32,\n",
       " 'j': 33,\n",
       " 'q': 34,\n",
       " 'x': 35,\n",
       " 'z': 36,\n",
       " '3': 37,\n",
       " '&': 38,\n",
       " '$': 39}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ed7426bc-b797-4ed7-9c73-03e1a0eaef4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_id = len(tokenizer.word_index)\n",
    "max_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "174ad237-8600-432b-8cb8-0a716cc9188e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115394"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_size = tokenizer.document_count\n",
    "dataset_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52848de1-d9e4-47b8-b00a-9e16d93794c3",
   "metadata": {},
   "source": [
    "So the tokenizer can be fit to text and it will create a word_index hashtable aka dict for each char or word. Then you can easily map texts to sequences and vice versa. Let's create our encoded data now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8800d66-9fe3-4d10-9e8b-cc8b1f76bb11",
   "metadata": {},
   "source": [
    "Subtract by 1 so that our enocded indices will be from 0 to 38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8411488c-fb95-45b6-8683-bcc6bd3098c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "[encoded] = np.array(tokenizer.texts_to_sequences([shakespeare_text])) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "335072b1-8ba5-497f-bcca-500954da44fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1115394,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7a6b250a-b112-46db-8301-87ea4a03d854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428f6fdd-a71a-4059-9949-2d52e0f0aeda",
   "metadata": {},
   "source": [
    "Now let's create our efficient datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8957c99e-3d71-4cb5-8739-1dc2d10f35f8",
   "metadata": {},
   "source": [
    "### Create Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad552073-02d7-4c43-a482-d8430b65b891",
   "metadata": {},
   "source": [
    "- Set train set to first 90% of text\n",
    "- Create dataset with windows of 100 characters\n",
    "    - Window size of 101 because target is next char\n",
    "- Flat map with batch on windows\n",
    "- Shuffle\n",
    "- Batch datset\n",
    "- Split input and target data\n",
    "- Apply one hot encoding to inputs\n",
    "- Prefetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "82fe3a66-e2c5-4c61-a843-f0b3b05e390c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1003854"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = dataset_size * 90 // 100\n",
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "94ba8499-22bc-4dbb-a39d-106a35c65230",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dcecd7-276b-401a-b46b-6297efdf5d97",
   "metadata": {},
   "source": [
    "Now let's get windows of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e8d60d95-5821-4b45-a430-6a8340ae0f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 100\n",
    "window_length = n_steps + 1\n",
    "dataset = dataset.window(window_length, shift=1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0c2c1c-eba6-4f70-8f1c-b706605b37e2",
   "metadata": {},
   "source": [
    "This creates a dataset of window datasets (yes each window is a dataset). To get just one dataset and convert windows to tensors, we need to use `flat_map` and batch each window to it's own size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "327c07ae-d340-477b-8c9c-9105c3db3c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.flat_map(lambda window: window.batch(window_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54154750-72ab-420e-bafc-8fb0aa710b9a",
   "metadata": {},
   "source": [
    "Now let's shuffle our windows and then batch them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8f9c6775-25c9-448a-83c0-1896920e0b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "dataset = dataset.shuffle(10000).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6a4b22-bcee-4fda-a0d0-8890a2d309f1",
   "metadata": {},
   "source": [
    "Let's split our data into input and target sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e905b1f4-7851-4c6f-aeb0-ffed54ebafe9",
   "metadata": {},
   "source": [
    "Shape of our data: `(batch_size, 101)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e2f5f3b2-506f-4e60-94a4-18b7833c43b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855d5de3-1520-4a82-890a-3d3b43346a06",
   "metadata": {},
   "source": [
    "Now let's apply one hot to our inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40be0ff6-1366-425e-8344-7bbf32881be2",
   "metadata": {},
   "source": [
    "Shape of our data: `(input (batch_size, 100, 1), target (batch_size, 100, 1))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cc12a895-2bc5-46c2-8703-f47dad55db9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda X_batch, Y_batch:\n",
    "                          (tf.one_hot(X_batch, max_id), Y_batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4620815d-7234-4954-b468-6551d7270bd7",
   "metadata": {},
   "source": [
    "Finally, let's prefetch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "909f7f5d-db8a-404d-bc29-30675a272113",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2945943-5522-41ef-9e05-74f5ef91cec3",
   "metadata": {},
   "source": [
    "### Model Arch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b1129d-ad2a-41ca-ba46-4c12e506208d",
   "metadata": {},
   "source": [
    "Let's use two GRU layers with 128 units each for long term memory. Add 20% dropout to both inputs and hidden states to prevent unstable gradients since this model will run through 100 steps or 100 layers when unrolled (which is pretty deep). Finally, we have a timedistributed dense layer (which means it will output for every step, not just last output) that will output 39 probabilities for the 39 possible characters using a softmax activation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a15136-e8a5-45b8-997d-f0c7f5573377",
   "metadata": {},
   "source": [
    "- 2 GRU layers, 128 units, 20% dropout\n",
    "- Dense layer, 39 units, softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1ff7d2-e480-493e-afe6-da920958ed1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id],\n",
    "                     dropout=0.2, recurrent_dropout=0.2),\n",
    "    keras.layers.GRU(128, return_sequences=True,\n",
    "                     dropout=0.2, recurrent_dropout=0.2),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(max_id, \n",
    "                                                    activation=\"softmax\"))\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cc1a7f-bf2f-4b88-a67e-aea1b3d3c1bb",
   "metadata": {},
   "source": [
    "This model takes way too long to train, let's use a stateful model and just copy the weights over."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48b27fb-8cf6-496b-9f77-246716575934",
   "metadata": {},
   "source": [
    "### Stateful Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92eb5c6d-8700-4f05-8082-4c4715f94aba",
   "metadata": {},
   "source": [
    "Stateful means copying the last hidden state of the previous iteration over to the new iteration instead of using 0s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530edf07-9d2c-4688-ab0c-b1f9b54ca9b5",
   "metadata": {},
   "source": [
    "To do this we will need our batches to be consecutive, an easy way is to have batches of size 1. Also our windows will need to have a shift of n_steps (not n_steps + 1 since we only add 1 for the outputs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e229f137-ff06-410e-aad9-d532d09d9d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(None, None, 39), dtype=tf.float32, name=None), TensorSpec(shape=(None, None), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])\n",
    "dataset = dataset.window(window_length, shift=n_steps, drop_remainder=True)\n",
    "dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
    "dataset = dataset.batch(1) # no shuffle and batch of size 1\n",
    "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:])) # batches are just one window\n",
    "dataset = dataset.map(lambda X_batch, Y_batch: \n",
    "                      (tf.one_hot(X_batch, max_id), Y_batch)) # again, batches are just one window\n",
    "dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85186c7c-808d-4609-b50b-7010a497af80",
   "metadata": {},
   "source": [
    "But then we won't be able to take advantage of vectorization performance improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd7ecf3-7484-4e1f-a9ce-44792ef058fc",
   "metadata": {},
   "source": [
    "So, let's do this:\n",
    "- Split our data into 32 chunks in order\n",
    "- Window each dataset\n",
    "- Stack the datasets\n",
    "    - Each element should be a (32, 101) tensor\n",
    "    - The first element is the first 101 steps or first window of the 32 datasets\n",
    "    - No need to batch now, since it's already in batch shape after stacking\n",
    "- Split input and target\n",
    "- Apply one hot \n",
    "- Prefetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6eb2c90a-e777-4fbe-bfd8-5913ceb49594",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "encoded_parts = np.array_split(encoded[:train_size], batch_size)\n",
    "datasets = []\n",
    "for encoded_part in encoded_parts:\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(encoded_part)\n",
    "    dataset = dataset.window(window_length, shift=n_steps, drop_remainder=True)\n",
    "    dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
    "    datasets.append(dataset)\n",
    "dataset = tf.data.Dataset.zip(tuple(datasets)).map(lambda *windows: tf.stack(windows))\n",
    "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
    "dataset = dataset.map(\n",
    "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))\n",
    "dataset = dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fad3e50-8074-448d-87a8-f17104d831e4",
   "metadata": {},
   "source": [
    "Now let's train our model - we need to set stateful to True for our RNN layers. Also, we need to make sure to reset the state between epochs (because we don't want to have bias from previous epochs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b7e6ff49-71f8-48e9-ad90-7a65710234af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(128, batch_input_shape=[batch_size, None, max_id], \n",
    "                     return_sequences=True, stateful=True, \n",
    "                     dropout=0.2, recurrent_dropout=0.2),\n",
    "    keras.layers.GRU(128, \n",
    "                     return_sequences=True, stateful=True, \n",
    "                     dropout=0.2, recurrent_dropout=0.2),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(max_id, \n",
    "                                                    activation=\"softmax\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "207199c3-3128-49b3-a9d8-8303ec02afb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru (GRU)                   (32, None, 128)           64896     \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (32, None, 128)           99072     \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (32, None, 39)           5031      \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 168,999\n",
      "Trainable params: 168,999\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c130769d-0093-4233-bd9f-e27b93229ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "313/313 [==============================] - 37s 108ms/step - loss: 2.5950 - accuracy: 0.2640\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 2.2225 - accuracy: 0.3486\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 2.2374 - accuracy: 0.3464\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 33s 105ms/step - loss: 2.3146 - accuracy: 0.3284\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 33s 106ms/step - loss: 1.9202 - accuracy: 0.4258\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 33s 105ms/step - loss: 1.8669 - accuracy: 0.4409\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 32s 102ms/step - loss: 1.8276 - accuracy: 0.4509\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 32s 104ms/step - loss: 1.7973 - accuracy: 0.4590\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 32s 101ms/step - loss: 1.7740 - accuracy: 0.4650\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 31s 100ms/step - loss: 1.7526 - accuracy: 0.4700\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 32s 101ms/step - loss: 1.7722 - accuracy: 0.4654\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 32s 102ms/step - loss: 1.7828 - accuracy: 0.4632\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 32s 102ms/step - loss: 1.7581 - accuracy: 0.4699\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 32s 101ms/step - loss: 1.8498 - accuracy: 0.4466\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 31s 100ms/step - loss: 1.7950 - accuracy: 0.4599\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 32s 101ms/step - loss: 1.7586 - accuracy: 0.4689\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 32s 101ms/step - loss: 1.8569 - accuracy: 0.4434\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 32s 103ms/step - loss: 1.8825 - accuracy: 0.4365\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 32s 101ms/step - loss: 1.8468 - accuracy: 0.4452\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 32s 102ms/step - loss: 1.7277 - accuracy: 0.4767\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 32s 101ms/step - loss: 1.6997 - accuracy: 0.4835\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 32s 101ms/step - loss: 1.6554 - accuracy: 0.4954\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 32s 102ms/step - loss: 1.6461 - accuracy: 0.4976\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 32s 101ms/step - loss: 1.6401 - accuracy: 0.4994\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 32s 102ms/step - loss: 1.6339 - accuracy: 0.5009\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 32s 101ms/step - loss: 1.6291 - accuracy: 0.5024\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 33s 104ms/step - loss: 1.6238 - accuracy: 0.5037\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 33s 104ms/step - loss: 1.6201 - accuracy: 0.5045\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 33s 104ms/step - loss: 1.6152 - accuracy: 0.5055\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 32s 102ms/step - loss: 1.6100 - accuracy: 0.5070\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 32s 102ms/step - loss: 1.6066 - accuracy: 0.5081\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 32s 101ms/step - loss: 1.6038 - accuracy: 0.5091\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 32s 102ms/step - loss: 1.6003 - accuracy: 0.5097\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 32s 102ms/step - loss: 1.5968 - accuracy: 0.5106\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 32s 102ms/step - loss: 1.5941 - accuracy: 0.5109\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 32s 102ms/step - loss: 1.5909 - accuracy: 0.5118\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 33s 104ms/step - loss: 1.5884 - accuracy: 0.5128\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 32s 102ms/step - loss: 1.5860 - accuracy: 0.5131\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 32s 104ms/step - loss: 1.5827 - accuracy: 0.5145\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 33s 105ms/step - loss: 1.5806 - accuracy: 0.5147\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 33s 105ms/step - loss: 1.5781 - accuracy: 0.5154\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 33s 106ms/step - loss: 1.5764 - accuracy: 0.5159\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 33s 105ms/step - loss: 1.5747 - accuracy: 0.5168\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 33s 106ms/step - loss: 1.5715 - accuracy: 0.5174\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 35s 110ms/step - loss: 1.5703 - accuracy: 0.5170\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 34s 109ms/step - loss: 1.5670 - accuracy: 0.5177\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 33s 106ms/step - loss: 1.5675 - accuracy: 0.5181\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 33s 106ms/step - loss: 1.5643 - accuracy: 0.5188\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 33s 105ms/step - loss: 1.5624 - accuracy: 0.5195\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 1.5611 - accuracy: 0.5194\n"
     ]
    }
   ],
   "source": [
    "# reset states between epochs\n",
    "class ResetStatesCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_begin(self, epoch, logs):\n",
    "        self.model.reset_states()\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(dataset, epochs=50,\n",
    "                    callbacks=[ResetStatesCallback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d53c77d-a2ad-4825-8b13-18c9d7309ca3",
   "metadata": {},
   "source": [
    "After training this, let's now save the weights and copy to the stateless model (so we can predict on batches of any size, not just 32)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "666036bf-cae5-41b0-8175-393c9c72f4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR = os.path.join(\".\", \"_models\", \"15_nlp\")\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "model.save_weights(os.path.join(SAVE_DIR, \"shakespeare_rnn_weights.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fe176b0d-911b-4940-b3ca-c39ba0d0460d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id],\n",
    "                     dropout=0.2, recurrent_dropout=0.2),\n",
    "    keras.layers.GRU(128, return_sequences=True,\n",
    "                     dropout=0.2, recurrent_dropout=0.2),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(max_id, \n",
    "                                                    activation=\"softmax\"))\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "048715a3-c437-4bfd-8a5d-a9cdfb1eb387",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(os.path.join(SAVE_DIR, \"shakespeare_rnn_weights.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58c3993-4fa0-486f-b382-07e51fd4a204",
   "metadata": {},
   "source": [
    "### Generate Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227b27f3-d3e0-498b-83e4-5ee03be748ac",
   "metadata": {},
   "source": [
    "To generate new shakespearean text:\n",
    "- Preprocess input text\n",
    "    - text to seq encode, subtract 1 from indices, to one hot\n",
    "- Predict next char probas\n",
    "- Randomly select a char using probas\n",
    "    - Add a temperature var to control how much variability you want\n",
    "- Convert selected char index to char\n",
    "    - Add 1, seq to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f41a57c8-e7b8-44ca-8534-3c17a9e91a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    encoded_text = np.array(tokenizer.texts_to_sequences([text]))\n",
    "    return tf.one_hot(encoded_text - 1, max_id)\n",
    "\n",
    "def next_char(model, text, temperature):\n",
    "    X_new = preprocess(text)\n",
    "    y_proba = model.predict(X_new, verbose=0)[0, -1:, :] # first batch, last step's output (aka last char), all probas\n",
    "    rescaled_logits = tf.math.log(y_proba) / temperature\n",
    "    char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n",
    "    return tokenizer.sequences_to_texts(char_id.numpy())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e33b3f1-fbed-4a17-962d-3142a5b205c0",
   "metadata": {},
   "source": [
    "Now let's create a function that generates `n_chars` chars of shakespearean text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b2cd7865-1d08-4f69-942c-c2fdf053fe11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shakespearean_text(model, seed_text, n_chars=50, temperature=1):\n",
    "    text = seed_text\n",
    "    for _ in range(n_chars):\n",
    "        text += next_char(model, text, temperature)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8aa6b0e-9268-4d55-adae-91fdec7159fc",
   "metadata": {},
   "source": [
    "Let's try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f7ff667b-f502-40f8-8c83-a3edf0c75a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ter:\n",
      "the seem the contraction of the court of the c\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"t\"\n",
    "print(shakespearean_text(model, seed_text, temperature=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e51a0f9c-adeb-4fd6-8f2e-d48f409f851e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t, bear for the\n",
      "good more one with your triar:\n",
      "nor,\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"t\"\n",
    "print(shakespearean_text(model, seed_text, temperature=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a64583f6-3559-41f0-b733-9baaf5443a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t, ly yearss, margand?\n",
      "ty-murr incewertess, kness y\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"t\"\n",
    "print(shakespearean_text(model, seed_text, temperature=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b106a4e-591d-4649-a08f-c6b5b48bb7d6",
   "metadata": {},
   "source": [
    "Cool! Let's try using a longer seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8eeb39ed-7c20-4671-aa14-592b311b09a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamlet said thou are\n",
      "since to serve go alive a timplint of such gentlemans,\n",
      "the suition warwick. then!\n",
      "him thou best one thy fortune one hisband.\n",
      "\n",
      "all:\n",
      "i will go should being give my cieizen's or thou\n",
      "so cursed wife with a a.---\n",
      "\n",
      "bygy:\n",
      "aid you had be rather, our conession that?\n",
      "\n",
      "sicinius:\n",
      "ha, sheve i horse of a lunious\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"Hamlet said thou are\"\n",
    "print(shakespearean_text(model, seed_text, n_chars=300, temperature=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bcc8fa-4181-4597-b034-d1dfbe82b361",
   "metadata": {},
   "source": [
    "## IMDB Review Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a733ddf-0d96-4078-a86d-ea664a71a033",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e74aa6bc-2dfa-4c2a-b223-1ca533cc05dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets, info = tfds.load(\"imdb_reviews\", as_supervised=True, with_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a38c125b-7bc7-4ff2-adfc-892a13f9d0a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Split('train'): <SplitInfo num_examples=25000, num_shards=1>,\n",
       " Split('test'): <SplitInfo num_examples=25000, num_shards=1>,\n",
       " Split('unsupervised'): <SplitInfo num_examples=50000, num_shards=1>}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info.splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c4d9ee02-5126-4d93-8348-7d4cfd9b15ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = info.splits[\"train\"].num_examples\n",
    "train_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f3d7c7-61b4-4544-b893-3a08d6f9bb10",
   "metadata": {},
   "source": [
    "Let's look at what the input data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3bea98a6-19fb-4be4-a419-2f50cbddb0db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <PrefetchDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
       " 'test': <PrefetchDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
       " 'unsupervised': <PrefetchDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "cf3f94ce-fada-43b2-871c-67f10a8a84eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "5f606e9a-0d9f-4fd4-b821-35c58897581a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'In this film we have the fabulous opportunity to see what happened to Timon and Pumbaa in the film when they are not shown - which is a lot! This film even goes back to before Simba and (presumbably) just after the birth of Kiara. <br /><br />Quite true to the first film, \"Lion King 1/2 (or Lion King 3 in other places)\" is a funny, entertaining, exciting and surprising film (or sequel if that\\'s what you want to call it). A bundle of surprises and hilarity await for you!<br /><br />While Timon and Pumbaa are watching a film at the cinema (with a remote control), Timon and Pumbaa have an argument of what point of \"The Lion King\" they are going to start watching, as Timon wants to go to the part when he and Pumbaa come in and Pumbaa wants to go back to the beginning. They have a very fair compromise of watching the film of their own story, which is what awaits... It starts with Timon\\'s first home...<br /><br />For anyone with a good sense of humour who liked the first films of just about any age, enjoy \"Lion King 1/2\"! :-)'>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for x, y in dataset.take(100).shuffle(100):\n",
    "    pass\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9814f1ce-cfb7-49bb-9218-d89514a236fe",
   "metadata": {},
   "source": [
    "We need to preprocess the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "dceb39b2-4435-4426-8124-39e655c8f01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(X_batch, y_batch):\n",
    "    X_batch = tf.strings.substr(X_batch, 0, 300) # truncate every review to first 300 chars\n",
    "    X_batch = tf.strings.regex_replace(X_batch, b\"<br\\\\s*/?>\", b\" \") # replace <br /> with whitespace\n",
    "    X_batch = tf.strings.regex_replace(X_batch, b\"[^a-zA-Z']\", b\" \") # replace anything that is not a-z, A-Z, or ' \n",
    "                                                                     # with whitespace\n",
    "    X_batch = tf.strings.split(X_batch) # create a sequence of words split by whitespace\n",
    "    return X_batch.to_tensor(default_value=b\"<pad>\"), y_batch # pad uneven ragged tensor so that we will have a dense tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779085f3-0c03-4f64-a93e-fb7b1e37452d",
   "metadata": {},
   "source": [
    "Now let's encode the words to ids\n",
    "- Create a vocabulary w/ Counter\n",
    "- Create a lookup table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cb6b11-b565-4371-8fb4-7f903960b177",
   "metadata": {},
   "source": [
    "Create a vocabulary in descending order most common to least common words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "bd203fab-9d61-4c6c-8580-484c26e1d12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "vocabulary = Counter()\n",
    "for X_batch, y_batch in dataset.batch(batch_size).map(preprocess):\n",
    "    for review in X_batch:\n",
    "        vocabulary.update(list(review.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "76125d69-727b-432e-a078-0d4d94cae19d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(b'<pad>', 214309),\n",
       " (b'the', 61137),\n",
       " (b'a', 38564),\n",
       " (b'of', 33983),\n",
       " (b'and', 33431)]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary.most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b40173-d1e2-462b-bfaa-1a5bfd1b37ee",
   "metadata": {},
   "source": [
    "Looks about right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "4744daa8-bdea-4668-adb1-8545e9c93f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53893"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "9e3afd7a-b8d6-44d1-b632-a3ecdf5e5721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(b'Legion', 7),\n",
       " (b'Republic', 7),\n",
       " (b'Cassie', 7),\n",
       " (b'hallucinations', 7),\n",
       " (b'Clinton', 7)]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary.most_common(10005)[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4b880c-9f77-4596-812c-833691a4317a",
   "metadata": {},
   "source": [
    "Let's just use the 10000 most common and use 1000 oov buckets for any other possible characters (probably don't even need 1000 since each sequence is only 300 words max)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "8d00c7b1-fb65-49e7-88f2-7e79d5d74c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "truncated_vocabulary = [word for word, count in vocabulary.most_common(vocab_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "c24f52fd-275b-437f-8b3a-a8173f50ec22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(truncated_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "d5a167d9-2710-411e-b7a4-70010a50c63d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'<pad>', b'the', b'a', b'of', b'and']"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truncated_vocabulary[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc061a92-6ecd-450c-bda1-88968e12b804",
   "metadata": {},
   "source": [
    "Create a lookup table initializer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "7f1b66a7-566c-47bb-81c4-320aa52c0612",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = tf.constant(truncated_vocabulary)\n",
    "word_ids = tf.range(len(truncated_vocabulary), dtype=tf.int64)\n",
    "vocab_init = tf.lookup.KeyValueTensorInitializer(words, word_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4090d967-fade-43c1-bf24-d3d6f3f44c7b",
   "metadata": {},
   "source": [
    "Create a lookup table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "527efd99-e61b-4941-9f46-a9f54855cdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_oov_buckets = 1000\n",
    "table = tf.lookup.StaticVocabularyTable(vocab_init, num_oov_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "173c0b2e-f959-4da1-8a47-aae69dd98d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 8), dtype=int64, numpy=array([[   22,    12,  1488,   175, 10716,  1831,   167,     0]])>"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = tf.constant([b\"This movie sucks real fucking ass man <pad>\".split()])\n",
    "table.lookup(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2794d3fa-b9e9-4977-9bfc-466bf96d407f",
   "metadata": {},
   "source": [
    "Now let's map the lookup table to each input sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "2577f4cb-1eb7-487c-a653-a65b8f312c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_words(X_batch, y_batch):\n",
    "    return table.lookup(X_batch), y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fb0114-58f7-4621-984c-4ef1743d9c7a",
   "metadata": {},
   "source": [
    "### Create Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f69d71-290f-46f3-bb8f-f0a6f6952833",
   "metadata": {},
   "source": [
    "Now let's wrap everything up together\n",
    "- Shuffle data\n",
    "- Batch the data\n",
    "- Preprocess text\n",
    "- Encode words\n",
    "- Prefetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "e3143e00-26ed-4156-bb14-a21d1a83362c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test = tfds.load(\"imdb_reviews\", as_supervised=True, split=[\"train\", \"test[:50%]\", \"test[50%:]\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "75622545-57fa-43dd-8ed7-68aeccb17d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_set = train.shuffle(10000).batch(batch_size).map(preprocess).map(encode_words).prefetch(1)\n",
    "valid_set = valid.batch(batch_size).map(preprocess).map(encode_words).prefetch(1)\n",
    "test_set = test.batch(batch_size).map(preprocess).map(encode_words).prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8673ee4b-5a8a-44ab-abd1-19efb4d3dfa6",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3d29bf-cf44-4e17-b49b-ad5a2f5590a0",
   "metadata": {},
   "source": [
    "We need to embed our word sequences for the model to learn good patterns and fast.\n",
    "- Input (batch_size, seq_length)\n",
    "- Embed (batch_size, seq_length, embed_dimen)\n",
    "- GRU\n",
    "- GRU\n",
    "- Dense Binary final output only (batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "fcc634f8-5a09-4fe3-b1f3-f4001ed0f3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dimen = 128\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Embedding(vocab_size + num_oov_buckets, \n",
    "                          embed_dimen, input_shape=[None]),\n",
    "    keras.layers.Conv1D(filters=embed_dimen, kernel_size=2, strides=2),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.GRU(128, return_sequences=True, \n",
    "                     dropout=0.2, recurrent_dropout=0.2),\n",
    "    keras.layers.GRU(128, \n",
    "                     dropout=0.2, recurrent_dropout=0.2),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "791e0308-cbe0-4d02-86c8-e5fb3935005a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "f3869047-71d0-440c-b557-f177b59eca55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 53s 62ms/step - loss: 0.5647 - accuracy: 0.6964\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 50s 64ms/step - loss: 0.3691 - accuracy: 0.8373\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 49s 63ms/step - loss: 0.2288 - accuracy: 0.9086\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 49s 62ms/step - loss: 0.1298 - accuracy: 0.9524\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 48s 62ms/step - loss: 0.0761 - accuracy: 0.9731\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe7f926bf40>"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_set, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "a4e8eca9-4318-4045-b7fc-e20faf6f0ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 9s 10ms/step - loss: 1.0188 - accuracy: 0.7404\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.018828272819519, 0.7404000163078308]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacffeb3-a9b0-40fd-8ed7-c8ff0822a403",
   "metadata": {},
   "source": [
    "Seems like it overfit. Let's use masks to get rid of padding from the learning process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f73239-9f3b-4991-8665-6fac9a9add52",
   "metadata": {},
   "source": [
    "### Model Masking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296c35b0-326c-4f5b-a0d5-aa8f91e1315f",
   "metadata": {},
   "source": [
    "Using a mask to omit input values that equal 0, (id 0 is `<pad>`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "e66ea5bb-8c97-4496-8ecd-88e35ebf4972",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.layers.Input(shape=[None])\n",
    "mask = keras.layers.Lambda(lambda inputs: K.not_equal(inputs, 0))(inputs) # returns True for all non zero inputs\n",
    "z = keras.layers.Embedding(vocab_size + num_oov_buckets, embed_dimen)(inputs)\n",
    "z = keras.layers.GRU(128, return_sequences=True)(z, mask=mask)\n",
    "z = keras.layers.GRU(128)(z, mask=mask)\n",
    "outputs = keras.layers.Dense(1, activation=\"sigmoid\")(z)\n",
    "model = keras.Model(inputs=[inputs], outputs=[outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "9cb9f9b5-8708-40a8-b058-e8ef83bbfe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d803d9cb-6a25-473d-b552-031591f15790",
   "metadata": {},
   "source": [
    "Let's add tensorboard callback for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "55762143-1445-45ba-9706-94803d00a122",
   "metadata": {},
   "outputs": [],
   "source": [
    "TENSORBOARD_DIR = os.path.join(\".\", \"_tf_logs\", \"15_nlp\")\n",
    "os.makedirs(TENSORBOARD_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "f0f4f5f5-579f-4408-873e-fa606858e39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./_tf_logs/15_nlp/imdb_masked_model_run_00001\n"
     ]
    }
   ],
   "source": [
    "run_index = 1\n",
    "run_logdir = os.path.join(TENSORBOARD_DIR, \"imdb_masked_model_run_{:05d}\".format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(log_dir=run_logdir, embeddings_freq=10)\n",
    "print(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "e20072d2-b5dd-4df7-be90-e84e928468a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=5)\n",
    "lr_scheduler_cb = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "15d98de4-cb21-4942-921e-162e1a23b727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 82s 96ms/step - loss: 0.5569 - accuracy: 0.7042 - val_loss: 0.4925 - val_accuracy: 0.7590 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 69s 88ms/step - loss: 0.3775 - accuracy: 0.8358 - val_loss: 0.4883 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 0.2726 - accuracy: 0.8907 - val_loss: 0.5749 - val_accuracy: 0.7567 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 0.1348 - accuracy: 0.9521 - val_loss: 0.8755 - val_accuracy: 0.7502 - lr: 5.0000e-04\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 72s 92ms/step - loss: 0.0601 - accuracy: 0.9823 - val_loss: 1.0464 - val_accuracy: 0.7469 - lr: 2.5000e-04\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 69s 89ms/step - loss: 0.0301 - accuracy: 0.9933 - val_loss: 1.2488 - val_accuracy: 0.7455 - lr: 1.2500e-04\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 69s 88ms/step - loss: 0.0202 - accuracy: 0.9962 - val_loss: 1.3038 - val_accuracy: 0.7438 - lr: 6.2500e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe7f8db1450>"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_set, epochs=10,\n",
    "          validation_data=valid_set,\n",
    "          callbacks=[tensorboard_cb, early_stopping_cb, lr_scheduler_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0c522c-95c1-4ecc-adb5-935f11687dc0",
   "metadata": {},
   "source": [
    "Using tensorboard, we can visualize the closest embeddings to the two words below. Let's see what words their neighbors are!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "f3285c85-4ad7-43cf-8e03-9ca0bd535566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int64, numpy=array([438, 260])>"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_words = tf.constant([\"amazing\", \"awful\"])\n",
    "table.lookup(sample_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "c23c2ac1-d057-4de5-8dfb-79c1a2340bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100 closest neighbors including amazing itself\n",
    "amazing_neighbor_ids = [438,674,332,327,269,284,325,1498,813,93,687,107,1573,2719,1291,577,902,870,1921,751,68,783,10126,2304,2197,2554,3101,1238,1015,3369,2474,7271,5496,2811,592,2440,2756,3093,1744,142,3530,2830,849,5639,434,6034,3925,3665,2463,2359,335,3454,1172,6188,4264,376,3762,1982,8960,8737,1196,3977,1597,276,1519,10035,2489,2169,1124,3051,4542,2772,2672,1166,579,1499,5808,1030,3350,2821,6080,2075,1040,4482,1542,3559,2931,3173,5640,4556,1618,7308,2137,3792,6371,8059,8326,9408,695,5392,3180]\n",
    "\n",
    "# 100 closest neighbors including awful itself\n",
    "awful_neighbor_ids = [260,143,1044,302,396,981,731,313,420,450,1069,1256,388,1572,788,2503,972,1669,1724,537,2893,631,966,623,1329,1619,908,3175,2523,2912,2786,460,2149,2261,1488,1129,749,391,988,1927,221,514,498,1339,3829,2841,1882,853,633,1200,1361,1052,10838,4227,1657,4736,8873,3082,2364,1037,2530,1701,1184,5948,5242,1022,1814,2232,2500,3886,2386,2621,3116,624,3512,880,1702,805,4708,1464,5311,728,1666,2736,3599,961,4834,6331,2130,5558,1065,2920,493,4003,5134,2432,356,3305,3730,5277,8640]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6113b00c-9365-41c7-ac76-9a7f5353b42d",
   "metadata": {},
   "source": [
    "Now let's see what words they are!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "f87fcba6-f4fb-4117-917b-bd8718addcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazing_neighbors = [str(truncated_vocabulary[id_]) for id_ in amazing_neighbor_ids if id_ < 10000]\n",
    "awful_neighbors = [str(truncated_vocabulary[id_]) for id_ in awful_neighbor_ids if id_ < 10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "8feb36b1-bdde-478e-9295-449b4881cc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'amazing'           b'awful'\n",
      "b'fantastic'         b'worst'\n",
      "b'favorite'          b'pathetic'\n",
      "b'wonderful'         b'terrible'\n",
      "b'excellent'         b'worse'\n",
      "b'loved'             b'fails'\n",
      "b'enjoyed'           b'poorly'\n",
      "b'underrated'        b'boring'\n",
      "b'unique'            b'horrible'\n",
      "b'best'              b'waste'\n",
      "b'enjoyable'         b'dumb'\n",
      "b'love'              b'laughable'\n",
      "b'wonderfully'       b'stupid'\n",
      "b'extraordinary'     b'unfunny'\n",
      "b'touching'          b'weak'\n",
      "b'simple'            b'tedious'\n",
      "b'awesome'           b'disappointment'\n",
      "b'Great'             b'bottom'\n",
      "b'feelings'          b'promising'\n",
      "b'masterpiece'       b'crap'\n",
      "b'great'             b'WORST'\n",
      "b'superb'            b'Unfortunately'\n",
      "b'refreshing'        b'mess'\n",
      "b'Excellent'         b'ridiculous'\n",
      "b'captured'          b'redeeming'\n",
      "b'Wonderful'         b'lacks'\n",
      "b'plenty'            b'badly'\n",
      "b'funniest'          b'stinker'\n",
      "b'stellar'           b'Worst'\n",
      "b'friendship'        b'turkey'\n",
      "b'limitations'       b'idiotic'\n",
      "b'advanced'          b'disappointed'\n",
      "b\"today's\"           b'atrocious'\n",
      "b'hilarious'         b'ruined'\n",
      "b'hooked'            b'sucks'\n",
      "b'Dirty'             b'pointless'\n",
      "b'subtitles'         b'dull'\n",
      "b'soul'              b'poor'\n",
      "b'still'             b'wasted'\n",
      "b'timeless'          b'wooden'\n",
      "b'Bourne'            b'minutes'\n",
      "b'animated'          b'supposed'\n",
      "b'Pushing'           b'problem'\n",
      "b'perfect'           b'excuse'\n",
      "b'Twice'             b'flop'\n",
      "b'Novak'             b'Seagal'\n",
      "b'unforgettable'     b'hype'\n",
      "b'Nancy'             b'cover'\n",
      "b'Matthau'           b'predictable'\n",
      "b'together'          b'unbelievable'\n",
      "b'soccer'            b'painful'\n",
      "b'beautifully'       b'writers'\n",
      "b'Trey'              b'ignorant'\n",
      "b'Holes'             b'pretentious'\n",
      "b'enjoy'             b'tripe'\n",
      "b'Ramones'           b'REVIEW'\n",
      "b'Jackie'            b'unwatchable'\n",
      "b'teller'            b'Seriously'\n",
      "b'Finch'             b'unfortunately'\n",
      "b'knowing'           b'remotely'\n",
      "b'Gerard'            b'confused'\n",
      "b'singing'           b'producers'\n",
      "b'performance'       b'unintentional'\n",
      "b'unusual'           b'skits'\n",
      "b'Carrey'            b'total'\n",
      "b'packed'            b'pile'\n",
      "b'genius'            b'MST'\n",
      "b'stylish'           b'amateurish'\n",
      "b'widow'             b'abysmal'\n",
      "b'complicated'       b'offensive'\n",
      "b'pleased'           b'Terrible'\n",
      "b'surprisingly'      b'werewolf'\n",
      "b'heart'             b'bunch'\n",
      "b'pleasure'          b'Uwe'\n",
      "b'Antwone'           b'Is'\n",
      "b'gem'               b'crappy'\n",
      "b'Elvira'            b'falls'\n",
      "b'Ralph'             b'hurts'\n",
      "b'Haines'            b'scientist'\n",
      "b'Emma'              b'wastes'\n",
      "b'overall'           b'lame'\n",
      "b'Paulie'            b'okay'\n",
      "b'journey'           b'vampires'\n",
      "b'attitude'          b'Otherwise'\n",
      "b'stays'             b'joke'\n",
      "b'flawless'          b'security'\n",
      "b'Daisies'           b'stupidest'\n",
      "b'Lily'              b'suck'\n",
      "b'scared'            b'eager'\n",
      "b'Suspense'          b'Bad'\n",
      "b'baseball'          b'irritating'\n",
      "b'profound'          b'let'\n",
      "b'Dressed'           b'intention'\n",
      "b'lighter'           b'atrocity'\n",
      "b'blends'            b'titles'\n",
      "b'embezzler'         b'money'\n",
      "b'highly'            b'Dolph'\n",
      "b'Thailand'          b'downhill'\n",
      "b'Rings'             b'unoriginal'\n"
     ]
    }
   ],
   "source": [
    "for amazing_neighbor, awful_neighbor in zip(amazing_neighbors, awful_neighbors):\n",
    "    print(\"{:20} {}\".format(amazing_neighbor, awful_neighbor))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03878b0-f7f1-4175-a6e9-f879c9539cdd",
   "metadata": {},
   "source": [
    "Wow, embeddings really do work!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e43af23-df1a-4fd7-9605-d02509500cea",
   "metadata": {},
   "source": [
    "### Pretrained Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90922a51-0c1f-4830-91a0-75eebd6323cf",
   "metadata": {},
   "source": [
    "Let's use Google's pretrained model for english sentence embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1287aa32-bce6-49b1-841d-d1c171d3c97d",
   "metadata": {},
   "source": [
    "This model does not require preprocessing, so let's create new datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "7ad1abdf-8943-465d-8d2a-3371583b59b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test = tfds.load(\"imdb_reviews\", as_supervised=True, \n",
    "                               split=[\"train+test[:50%]\", \"test[50%:75%]\", \"test[75%:]\"])\n",
    "\n",
    "batch_size = 32\n",
    "train_set = train.shuffle(10000).batch(batch_size).prefetch(1)\n",
    "valid_set = valid.batch(batch_size).prefetch(1)\n",
    "test_set = test.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0ec95d-eccc-41b4-9af6-8d43f837aab1",
   "metadata": {},
   "source": [
    "Now let's create our model using the tfhub model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "8a394442-6762-40dc-9f01-d899c7275b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TFHUB_CACHE_DIR\"] = os.path.join(\".\", \"my_tfhub_cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "1a4a0ed0-84d7-40e6-b98a-ff14a0422f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/nnlm-en-dim50/1\", output_shape=[50],\n",
    "                   input_shape=[], dtype=tf.string),\n",
    "    keras.layers.Dense(150, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "3c644ccf-775b-4257-9a30-cbb91d3d8766",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "43345c27-fc7a-491e-b157-9b3ce8ab7307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1172/1172 [==============================] - 6s 4ms/step - loss: 0.5538 - accuracy: 0.7198 - val_loss: 0.5285 - val_accuracy: 0.7402\n",
      "Epoch 2/5\n",
      "1172/1172 [==============================] - 4s 3ms/step - loss: 0.5259 - accuracy: 0.7393 - val_loss: 0.5220 - val_accuracy: 0.7470\n",
      "Epoch 3/5\n",
      "1172/1172 [==============================] - 4s 3ms/step - loss: 0.5201 - accuracy: 0.7456 - val_loss: 0.5104 - val_accuracy: 0.7491\n",
      "Epoch 4/5\n",
      "1172/1172 [==============================] - 4s 3ms/step - loss: 0.5165 - accuracy: 0.7462 - val_loss: 0.5126 - val_accuracy: 0.7507\n",
      "Epoch 5/5\n",
      "1172/1172 [==============================] - 4s 3ms/step - loss: 0.5140 - accuracy: 0.7477 - val_loss: 0.5543 - val_accuracy: 0.7232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe7dc6d7940>"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_set, epochs=5,\n",
    "          validation_data=valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "56e6b194-69d2-40e6-a3f8-56762d604c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "dd95f382-baab-4a6c-b6f1-ea8295cf7200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./_tf_logs/15_nlp/imdb_tfhub_model_run_00006\n"
     ]
    }
   ],
   "source": [
    "run_index = 6\n",
    "run_logdir = os.path.join(TENSORBOARD_DIR, \"imdb_tfhub_model_run_{:05d}\".format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(log_dir=run_logdir, embeddings_freq=2)\n",
    "print(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "e1f0c1dd-1487-4621-9c94-5c33544a17ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10)\n",
    "lr_scheduler_cb = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "8a721ef2-b900-46b5-82cc-250a5c269102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.5129 - accuracy: 0.7501 - val_loss: 0.5192 - val_accuracy: 0.7498 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "1172/1172 [==============================] - 4s 3ms/step - loss: 0.5115 - accuracy: 0.7498 - val_loss: 0.5135 - val_accuracy: 0.7514 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.5101 - accuracy: 0.7516 - val_loss: 0.5100 - val_accuracy: 0.7504 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "1172/1172 [==============================] - 4s 3ms/step - loss: 0.5080 - accuracy: 0.7519 - val_loss: 0.5195 - val_accuracy: 0.7443 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.5074 - accuracy: 0.7530 - val_loss: 0.5140 - val_accuracy: 0.7477 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "1172/1172 [==============================] - 4s 3ms/step - loss: 0.5025 - accuracy: 0.7535 - val_loss: 0.5072 - val_accuracy: 0.7525 - lr: 5.0000e-04\n",
      "Epoch 7/100\n",
      "1172/1172 [==============================] - 4s 4ms/step - loss: 0.5016 - accuracy: 0.7569 - val_loss: 0.5080 - val_accuracy: 0.7549 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "1172/1172 [==============================] - 4s 3ms/step - loss: 0.5012 - accuracy: 0.7574 - val_loss: 0.5081 - val_accuracy: 0.7534 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.4962 - accuracy: 0.7601 - val_loss: 0.5066 - val_accuracy: 0.7544 - lr: 2.5000e-04\n",
      "Epoch 10/100\n",
      "1172/1172 [==============================] - 4s 3ms/step - loss: 0.4953 - accuracy: 0.7604 - val_loss: 0.5083 - val_accuracy: 0.7515 - lr: 2.5000e-04\n",
      "Epoch 11/100\n",
      "1172/1172 [==============================] - 4s 4ms/step - loss: 0.4936 - accuracy: 0.7598 - val_loss: 0.5076 - val_accuracy: 0.7536 - lr: 2.5000e-04\n",
      "Epoch 12/100\n",
      "1172/1172 [==============================] - 4s 3ms/step - loss: 0.4933 - accuracy: 0.7634 - val_loss: 0.5082 - val_accuracy: 0.7544 - lr: 1.2500e-04\n",
      "Epoch 13/100\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.4918 - accuracy: 0.7624 - val_loss: 0.5063 - val_accuracy: 0.7565 - lr: 1.2500e-04\n",
      "Epoch 14/100\n",
      "1172/1172 [==============================] - 4s 3ms/step - loss: 0.4904 - accuracy: 0.7643 - val_loss: 0.5077 - val_accuracy: 0.7542 - lr: 1.2500e-04\n",
      "Epoch 15/100\n",
      "1172/1172 [==============================] - 4s 4ms/step - loss: 0.4890 - accuracy: 0.7648 - val_loss: 0.5068 - val_accuracy: 0.7558 - lr: 1.2500e-04\n",
      "Epoch 16/100\n",
      "1172/1172 [==============================] - 4s 3ms/step - loss: 0.4892 - accuracy: 0.7665 - val_loss: 0.5056 - val_accuracy: 0.7560 - lr: 6.2500e-05\n",
      "Epoch 17/100\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.4882 - accuracy: 0.7655 - val_loss: 0.5063 - val_accuracy: 0.7549 - lr: 6.2500e-05\n",
      "Epoch 18/100\n",
      "1172/1172 [==============================] - 4s 3ms/step - loss: 0.4884 - accuracy: 0.7628 - val_loss: 0.5065 - val_accuracy: 0.7542 - lr: 6.2500e-05\n",
      "Epoch 19/100\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.4869 - accuracy: 0.7648 - val_loss: 0.5085 - val_accuracy: 0.7541 - lr: 3.1250e-05\n",
      "Epoch 20/100\n",
      "1172/1172 [==============================] - 4s 3ms/step - loss: 0.4859 - accuracy: 0.7660 - val_loss: 0.5086 - val_accuracy: 0.7531 - lr: 3.1250e-05\n",
      "Epoch 21/100\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.4868 - accuracy: 0.7650 - val_loss: 0.5070 - val_accuracy: 0.7566 - lr: 1.5625e-05\n",
      "Epoch 22/100\n",
      "1172/1172 [==============================] - 4s 3ms/step - loss: 0.4851 - accuracy: 0.7654 - val_loss: 0.5057 - val_accuracy: 0.7557 - lr: 1.5625e-05\n",
      "Epoch 23/100\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.4856 - accuracy: 0.7678 - val_loss: 0.5077 - val_accuracy: 0.7542 - lr: 7.8125e-06\n",
      "Epoch 24/100\n",
      "1172/1172 [==============================] - 4s 3ms/step - loss: 0.4867 - accuracy: 0.7666 - val_loss: 0.5069 - val_accuracy: 0.7534 - lr: 7.8125e-06\n",
      "Epoch 25/100\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.4856 - accuracy: 0.7654 - val_loss: 0.5076 - val_accuracy: 0.7563 - lr: 3.9063e-06\n",
      "Epoch 26/100\n",
      "1172/1172 [==============================] - 4s 4ms/step - loss: 0.4857 - accuracy: 0.7674 - val_loss: 0.5065 - val_accuracy: 0.7550 - lr: 3.9063e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe8054888b0>"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_set, epochs=100,\n",
    "          validation_data=valid_set,\n",
    "          callbacks=[tensorboard_cb, early_stopping_cb, lr_scheduler_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "23f8c2ef-ee7d-412b-bfbc-8a0239fffa0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.08318325]], dtype=float32)"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([\"I really don't like this movie. It's horrible, terrible, disgusting, awful, bad.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "f995d697-ae55-4136-97a6-1dca2de57ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 42ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9896085]], dtype=float32)"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([\"This movie is great! I love her so much! Amazing!\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755b7b92-7781-4ca2-b713-aef794a92504",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba46f1e-851d-4f21-9827-a2fd44f6d449",
   "metadata": {},
   "source": [
    "## Embedded Reber Grammars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31c8366-15ad-44ae-b8ef-b3f69f2ca3bd",
   "metadata": {},
   "source": [
    "We need to first generate our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d126049-b314-4371-b2e0-15d78d8f9f8b",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695ce109-33de-487f-bb95-e1402acf03b9",
   "metadata": {},
   "source": [
    "Using random selection with uniform probabilities, let's try to create a function that generates an embedded reber grammar string."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe87536-23ff-4f84-aeb3-0b9451e53ed5",
   "metadata": {},
   "source": [
    "![reber_grammar](_images/reber_grammar.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a389ef-e845-44b8-9df0-bb3eaeac1d54",
   "metadata": {},
   "source": [
    "Each state represents an edge or edges of a vertice in a directed graph. Except the edges have values and the vertices don't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "a1963627-c73a-4030-bdfa-9497a6eb5aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_reber_grammar = [\n",
    "    [(\"B\", 1)], # starting edge: (B to vertex 1)\n",
    "    [(\"T\", 2), (\"P\", 3)], # vertex 1 has two outgoing edges: (T to vertex 2) and (P to vertex 3)\n",
    "    [(\"S\", 2), (\"X\", 4)], # vertex 2 has two outgoing edges: (S back to vertex 2) and (X to vertex 4)\n",
    "    [(\"T\", 3), (\"V\", 5)], # vertex 3 has two outgoing edges: (T back to vertex 3) and (V to vertex 5)\n",
    "    [(\"X\", 3), (\"S\", 6)], # vertex 4 has two outgoing edges: (X to vertex 3) and (S to vertex 6)\n",
    "    [(\"P\", 4), (\"V\", 6)], # vertex 5 has two outgoing edges: (P to vertex 4) and (V to vertex 6)\n",
    "    [(\"E\", None)], # vertex 6 has one outgoing edge: (E to end)\n",
    "]\n",
    "\n",
    "def generate_reber_string(grammar=default_reber_grammar):\n",
    "    vertex = 0 # starting from first edge (no vertex)\n",
    "    output = \"\"\n",
    "    while vertex != None: # iterate until vertex = None\n",
    "        n_edges = len(grammar[vertex]) # how many edges does our current vertex have?\n",
    "        edge = np.random.randint(n_edges) # if n_edges = 1, then edge will be 0 only\n",
    "        reber_value, vertex = grammar[vertex][edge] # get edge's value and update vertex to vertex it's pointing to\n",
    "        output += reber_value\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "9b23ba60-07ea-439e-8d25-3fd49c9406f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTXSE\n",
      "BPTVPSE\n",
      "BTXXVPXTTVPXVVE\n",
      "BPTVPXVVE\n",
      "BTSXSE\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    print(generate_reber_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d44c1c7-e0d5-4edc-b381-291e64ba15c4",
   "metadata": {},
   "source": [
    "Now let's use the embedded graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "56ef483e-e970-4a43-b82c-731229f09780",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_reber_grammar = [\n",
    "    [(\"B\", 1)], # starting edge: (B to vertex 1)\n",
    "    [(\"T\", 2), (\"P\", 3)], # vertex 1 has two outgoing edges: (T to vertex 2) and (P to vertex 3)\n",
    "    [(default_reber_grammar, 4)], # vertex 2 has one outgoing edge: (embedded reber to vertex 4)\n",
    "    [(default_reber_grammar, 5)], # vertex 3 has one outgoing edge: (embedded reber to vertex 5)\n",
    "    [(\"T\", 6)], # vertex 4 has one outgoing edge: (T to vertex 6)\n",
    "    [(\"P\", 6)], # vertex 5 has one outgoing edge: (P to vertex 6)\n",
    "    [(\"E\", None)], # vertex 6 has one outgoing edge: (E to end)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c335ed8-e7bd-41cf-8e8b-075144278405",
   "metadata": {},
   "source": [
    "We need to update our function so that it can recursively create reber strings if reber grammar is embedded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "e126c2a6-97d8-4fcd-9c81-940ebfd74541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_reber_string(grammar=embedded_reber_grammar):\n",
    "    vertex = 0 # starting from first edge (no vertex)\n",
    "    output = \"\"\n",
    "    while vertex != None: # iterate until vertex = None\n",
    "        n_edges = len(grammar[vertex]) # how many edges does our current vertex have?\n",
    "        edge = np.random.randint(n_edges) # if n_edges = 1, then edge will be 0 only\n",
    "        reber_value, vertex = grammar[vertex][edge] # get edge's value and update vertex to vertex it's pointing to\n",
    "        # if reber_value is a list - then it's an embedded graph\n",
    "        if isinstance(reber_value, list):\n",
    "            reber_value = generate_reber_string(reber_value) # we want to update value to the resulting reber string\n",
    "        output += reber_value\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "b56015a3-5201-4657-b4e2-411f0319d030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTBPTVVETE\n",
      "BPBTSXSEPE\n",
      "BTBPTTTVPSETE\n",
      "BPBPTVPSEPE\n",
      "BTBPTVVETE\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    print(generate_reber_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5982f35c-e022-41ae-b133-84b28b6c7bbb",
   "metadata": {},
   "source": [
    "Now we need to be able to generate strings that fail to follow the embedded reber grammar. There are many ways to do this, but what is the best way? The way that can cover the widest range? Generalize best?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1984a5f-5c53-4f0a-9168-18f3c81ee70d",
   "metadata": {},
   "source": [
    "A good way is to randomly change one char from a good string\n",
    "- Will present enough difficulty\n",
    "- Will cover a wide ranges of possible strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "693c573e-41dc-40fc-a872-6a95fbb79690",
   "metadata": {},
   "outputs": [],
   "source": [
    "POSSIBLE_CHARS = \"BEPSTVX\"\n",
    "\n",
    "def generate_corrupted_string(grammar=embedded_reber_grammar, chars=POSSIBLE_CHARS):\n",
    "    good_string = generate_string(grammar)\n",
    "    index = np.random.randint(len(good_string))\n",
    "    good_char = good_string[index]\n",
    "    bad_char = np.random.choice(sorted(set(chars) - set(good_char))) # randomly select a char that is different\n",
    "    return good_string[:index] + bad_char + good_string[index + 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "09807033-7765-4ceb-8720-282ba05d3fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTBPTVPSXTE\n",
      "BTBPTVPSVVETE\n",
      "BPBTSTXTVPSEPE\n",
      "BXBPVPSEPE\n",
      "BPBPVPSEPV\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    print(generate_corrupted_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fd00b0-a6a3-4b36-8779-c07b4b19041d",
   "metadata": {},
   "source": [
    "### Create Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c060088b-ac06-4e52-ba76-931d5e20ba8d",
   "metadata": {},
   "source": [
    "We want our train, valid, and test sets to have an equal number of positive and negative samples, so we must create a pos. list of tuples (string, 1) and a neg. list of tuples (string, 0) for each set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ade091-5fef-4079-8fb4-b202c43c22cd",
   "metadata": {},
   "source": [
    "We need to encode the strings to their indices so that we can embed the chars in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "76c33223-cf01-493c-9fb5-093f285fdc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_ids(s, chars=POSSIBLE_CHARS):\n",
    "    return [chars.index(c) for c in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "0dd24b72-a36c-4e35-ace7-626c5d184cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reber_dataset(size):\n",
    "    pos = [string_to_ids(generate_reber_string())\n",
    "           for _ in range(size // 2)]\n",
    "    neg = [string_to_ids(generate_corrupted_string())\n",
    "           for _ in range(size - size // 2)]\n",
    "    X = tf.ragged.constant(pos + neg, ragged_rank=1)\n",
    "    y = tf.constant(([1.] * len(pos)) + ([0.] * len(neg)))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "66d6b94b-0e70-4a38-a986-7b36d93aea3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_backend()\n",
    "\n",
    "train_set = tf.data.Dataset.from_tensor_slices(reber_dataset(20000)).shuffle(20000).batch(32).prefetch(1)\n",
    "valid_set = tf.data.Dataset.from_tensor_slices(reber_dataset(5000)).batch(32).prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5545f271-2bfb-41fa-a6f6-ce31830a8abc",
   "metadata": {},
   "source": [
    "Now let's create our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fa2917-2f8c-43c4-be3d-3b15fa5e438b",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc54a630-17b5-4b4b-8146-4814de95576e",
   "metadata": {},
   "source": [
    "- Embed input\n",
    "- GRU\n",
    "- Dense with 1 unit and activation is sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "5a34d0e9-f473-42f6-9eed-22ac5d1f5f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_backend()\n",
    "\n",
    "embed_dim = 5\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=[None], dtype=tf.int32, ragged=True),\n",
    "    keras.layers.Embedding(input_dim=len(POSSIBLE_CHARS), output_dim=embed_dim),\n",
    "    keras.layers.GRU(30),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "adb923fb-aec2-432c-bd6c-a941e08552c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "625/625 [==============================] - 8s 9ms/step - loss: 0.6794 - accuracy: 0.5433 - val_loss: 0.6532 - val_accuracy: 0.6138\n",
      "Epoch 2/20\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 0.6416 - accuracy: 0.5964 - val_loss: 0.6193 - val_accuracy: 0.6264\n",
      "Epoch 3/20\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 0.5772 - accuracy: 0.6683 - val_loss: 0.5322 - val_accuracy: 0.7602\n",
      "Epoch 4/20\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 0.3928 - accuracy: 0.8228 - val_loss: 0.2474 - val_accuracy: 0.9034\n",
      "Epoch 5/20\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 0.1133 - accuracy: 0.9679 - val_loss: 0.0781 - val_accuracy: 0.9824\n",
      "Epoch 6/20\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 0.0841 - accuracy: 0.9797 - val_loss: 0.0562 - val_accuracy: 0.9896\n",
      "Epoch 7/20\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 0.0240 - accuracy: 0.9948 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 7.9580e-04 - accuracy: 1.0000 - val_loss: 5.5282e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 4.0622e-04 - accuracy: 1.0000 - val_loss: 3.5847e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 2.8045e-04 - accuracy: 1.0000 - val_loss: 2.6720e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 2.1567e-04 - accuracy: 1.0000 - val_loss: 2.1220e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 1.7496e-04 - accuracy: 1.0000 - val_loss: 1.7587e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "625/625 [==============================] - 6s 9ms/step - loss: 1.4687e-04 - accuracy: 1.0000 - val_loss: 1.5018e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "625/625 [==============================] - 5s 9ms/step - loss: 1.2643e-04 - accuracy: 1.0000 - val_loss: 1.3029e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 1.1077e-04 - accuracy: 1.0000 - val_loss: 1.1511e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 9.8392e-05 - accuracy: 1.0000 - val_loss: 1.0290e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 8.8397e-05 - accuracy: 1.0000 - val_loss: 9.3088e-05 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 8.0161e-05 - accuracy: 1.0000 - val_loss: 8.4815e-05 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 7.3228e-05 - accuracy: 1.0000 - val_loss: 7.7783e-05 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 6.7403e-05 - accuracy: 1.0000 - val_loss: 7.1805e-05 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate=0.02, momentum = 0.95, nesterov=True)\n",
    "model.compile(loss=\"binary_crossentropy\", \n",
    "              optimizer=optimizer, \n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(train_set, epochs=20, \n",
    "                    validation_data=valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "3c4d4119-ea69-4eb8-b304-ab9b3ee151e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 345ms/step\n",
      "\n",
      "Estimated probability that these are Reber strings:\n",
      "BPBTSSSSSSSXXTTVPXVPXTTTTTVVETE: 0.01%\n",
      "BPBTSSSSSSSXXTTVPXVPXTTTTTVVEPE: 99.98%\n"
     ]
    }
   ],
   "source": [
    "test_strings = [\"BPBTSSSSSSSXXTTVPXVPXTTTTTVVETE\",\n",
    "                \"BPBTSSSSSSSXXTTVPXVPXTTTTTVVEPE\"]\n",
    "X_test = tf.ragged.constant([string_to_ids(s) for s in test_strings], ragged_rank=1)\n",
    "\n",
    "y_proba = model.predict(X_test)\n",
    "print()\n",
    "print(\"Estimated probability that these are Reber strings:\")\n",
    "for index, string in enumerate(test_strings):\n",
    "    print(\"{}: {:.2f}%\".format(string, 100 * y_proba[index][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dc631f-5a16-442c-8f65-623464a1180c",
   "metadata": {},
   "source": [
    "### Mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4584e9a-74fe-4737-b316-7be393d84624",
   "metadata": {},
   "source": [
    "- I did not double check my data generation function and my embedded grammar was wrong!\n",
    "- I used a way too complicated model - next time use a simple model and gradually increase complexity if the simple model doesn't work!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6ecbe5-3828-4df3-bcff-5f2fcfce3680",
   "metadata": {},
   "source": [
    "## Convert Date String"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3899cebc-b1a2-40b3-97fa-d9ad83f41931",
   "metadata": {},
   "source": [
    "We first need to generate date string data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22142547-9cb8-4e9d-b0f1-d5f70c77076d",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8039ee-c696-44c4-9862-531593dc8ff7",
   "metadata": {},
   "source": [
    "- Generate Random month, day, year\n",
    "- Return same date in input and output formats\n",
    "- Encode input and output strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "1856c188-c56c-4225-8bb0-07517b8ae947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "364878"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import date\n",
    "\n",
    "# year, month, day\n",
    "date(1000, 1, 1).toordinal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "6863bd1d-3bbe-45fa-9de1-faec320ceedb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3652059"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date(9999, 12, 31).toordinal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "f768ff2f-b48d-4e13-87ef-559fca44ddc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(9726, 3, 17)"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date.fromordinal(3652059 - 100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dc8e18-3ce2-427c-a5eb-1387d291195b",
   "metadata": {},
   "source": [
    "To generate our data\n",
    "- Set max and min dates\n",
    "- Numpy random to get random date btwn max and min\n",
    "- Format resulting date to string\n",
    "    - Input: `\"April 22, 2019\"`\n",
    "    - Target: `\"2019-04-22\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "49122961-c585-4eab-bc20-3a4866f66ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MONTHS = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\",\n",
    "          \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]\n",
    "\n",
    "def random_dates(n_dates):\n",
    "    min_date = date(1000, 1, 1).toordinal()\n",
    "    max_date = date(9999, 12, 31).toordinal()\n",
    "    \n",
    "    # select random date btwn min and max\n",
    "    ordinals = np.random.randint(max_date-min_date, size=n_dates) + min_date\n",
    "    dates = [date.fromordinal(ordinal) for ordinal in ordinals]\n",
    "    \n",
    "    # date to string formats\n",
    "    X = [MONTHS[dt.month - 1] + \" \" + dt.strftime(\"%d, %Y\") for dt in dates]\n",
    "    y = [dt.isoformat() for dt in dates]\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "id": "a64249f5-543a-4f83-82be-6d1c5a122857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input                    Target                   \n",
      "--------------------------------------------------\n",
      "March 26, 4682           4682-03-26               \n",
      "March 03, 8128           8128-03-03               \n",
      "December 23, 4998        4998-12-23               \n"
     ]
    }
   ],
   "source": [
    "n_dates = 3\n",
    "x_example, y_example = random_dates(n_dates)\n",
    "print(\"{:25s}{:25s}\".format(\"Input\", \"Target\"))\n",
    "print(\"-\" * 50)\n",
    "for idx in range(n_dates):\n",
    "    print(\"{:25s}{:25s}\".format(x_example[idx], y_example[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b0deb1-1cd6-49f7-b307-640f330a0b03",
   "metadata": {},
   "source": [
    "Now we need to encode our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "dcf8b9d9-9695-4f23-8f94-15a081915b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' ,0123456789ADFJMNOSabceghilmnoprstuvy'"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_CHARS = \"\".join(sorted(set(\"\".join(MONTHS) + \"0123456789, \")))\n",
    "INPUT_CHARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "6f5fdb1c-45dd-40f9-ae0a-66af7fc4fdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_CHARS = \"0123456789-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "739dc849-ee21-487c-ab15-2c5a93800b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_str_to_ids(date_str, chars):\n",
    "    return [chars.index(c) for c in date_str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "4187e9a0-d9f7-49f9-bf9a-7ad3649b5efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['June 20, 4110']\n",
      "['4110-06-20']\n"
     ]
    }
   ],
   "source": [
    "sample_input, sample_output = random_dates(1)\n",
    "print(sample_input)\n",
    "print(sample_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "c96a742a-c30b-4542-b698-ce8955099b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15, 35, 29, 23, 0, 4, 2, 1, 0, 6, 3, 3, 2]"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_str_to_ids(sample_input[0], INPUT_CHARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "4fe9025a-ebc8-43b9-86ca-c038d26b5a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 1, 1, 0, 10, 0, 6, 10, 2, 0]"
      ]
     },
     "execution_count": 589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_str_to_ids(sample_output[0], OUTPUT_CHARS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf53195-ddef-4b43-a615-834e5de451fd",
   "metadata": {},
   "source": [
    "### Create Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7957c6b-e3ed-4550-b559-98ec60a506f4",
   "metadata": {},
   "source": [
    "- Generate X and y len = `size` for train and valid\n",
    "- Shuffle train\n",
    "- Batch and prefetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "id": "a6a8c2ed-011e-473b-8774-a55647791fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_date_strs(date_strs, chars):\n",
    "    ids = [date_str_to_ids(input_str, chars) for input_str in date_strs]\n",
    "    ids = tf.ragged.constant(ids, ragged_rank=1)\n",
    "    return (ids + 1).to_tensor() # 0 for padding\n",
    "\n",
    "max_input_length = 18\n",
    "\n",
    "def prepare_date_strs_padded(date_strs):\n",
    "    X = encode_date_strs(date_strs, INPUT_CHARS)\n",
    "    if X.shape[1] < max_input_length:\n",
    "        X = tf.pad(X, [[0, 0], [0, max_input_length - X.shape[1]]])\n",
    "    return X\n",
    "\n",
    "def date_str_dataset(size):\n",
    "    X, Y = random_dates(size) # X (size, dtype=str), Y (size, dtype=str)\n",
    "    \n",
    "    return prepare_date_strs_padded(X), encode_date_strs(Y, OUTPUT_CHARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "id": "20b1b316-7f36-4ada-8a91-6ce185134768",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = tf.data.Dataset.from_tensor_slices(date_str_dataset(10000)).shuffle(10000).batch(32).prefetch(1)\n",
    "valid_set = tf.data.Dataset.from_tensor_slices(date_str_dataset(2000)).batch(32).prefetch(1)\n",
    "test_set = tf.data.Dataset.from_tensor_slices(date_str_dataset(2000)).batch(32).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "id": "504b787d-610d-4a9a-ae0e-88066298bfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_set.take(1):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "id": "597732f2-046b-4ceb-8a17-36e5f7d974d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 18), dtype=int32, numpy=\n",
       "array([[16, 36, 28, 38,  1,  3,  8,  2,  1,  5,  3, 10,  9,  0,  0,  0,\n",
       "         0,  0],\n",
       "       [13, 32, 33, 27, 28,  1,  5, 10,  2,  1,  7, 12, 11,  5,  0,  0,\n",
       "         0,  0],\n",
       "       [17, 21, 38,  1,  5, 12,  2,  1, 10,  8, 10,  6,  0,  0,  0,  0,\n",
       "         0,  0],\n",
       "       [13, 32, 33, 27, 28,  1,  3,  4,  2,  1,  6,  5,  9, 10,  0,  0,\n",
       "         0,  0],\n",
       "       [13, 32, 33, 27, 28,  1,  5,  4,  2,  1,  9, 10, 12, 11,  0,  0,\n",
       "         0,  0],\n",
       "       [18, 31, 37, 24, 29, 22, 24, 33,  1,  3,  7,  2,  1, 11,  4,  5,\n",
       "         7,  0],\n",
       "       [17, 21, 33, 23, 26,  1,  3, 12,  2,  1,  5,  8,  7, 12,  0,  0,\n",
       "         0,  0],\n",
       "       [15, 24, 22, 33, 36, 21, 33, 38,  1,  4,  8,  2,  1, 11,  3,  4,\n",
       "         3,  0],\n",
       "       [15, 24, 22, 33, 36, 21, 33, 38,  1,  3, 12,  2,  1, 11,  8, 11,\n",
       "         8,  0],\n",
       "       [17, 21, 38,  1,  3,  7,  2,  1,  7,  8,  9,  4,  0,  0,  0,  0,\n",
       "         0,  0],\n",
       "       [17, 21, 38,  1,  3, 12,  2,  1,  8,  3,  7, 11,  0,  0,  0,  0,\n",
       "         0,  0],\n",
       "       [15, 24, 22, 33, 36, 21, 33, 38,  1,  5,  9,  2,  1, 12,  8,  5,\n",
       "        10,  0],\n",
       "       [16, 21, 30, 36, 21, 33, 38,  1,  5,  8,  2,  1, 11,  4, 12,  7,\n",
       "         0,  0],\n",
       "       [16, 36, 28, 38,  1,  4, 10,  2,  1,  6,  5, 12,  9,  0,  0,  0,\n",
       "         0,  0],\n",
       "       [20, 24, 32, 35, 24, 29, 22, 24, 33,  1,  3,  4,  2,  1,  9,  3,\n",
       "         6,  6],\n",
       "       [17, 21, 33, 23, 26,  1,  3, 10,  2,  1,  9,  5,  8,  7,  0,  0,\n",
       "         0,  0],\n",
       "       [16, 36, 30, 24,  1,  3,  6,  2,  1,  4,  4, 11,  8,  0,  0,  0,\n",
       "         0,  0],\n",
       "       [15, 24, 22, 33, 36, 21, 33, 38,  1,  4,  6,  2,  1,  8,  8,  3,\n",
       "         6,  0],\n",
       "       [13, 32, 33, 27, 28,  1,  3,  4,  2,  1,  8,  9,  4,  3,  0,  0,\n",
       "         0,  0],\n",
       "       [14, 24, 23, 24, 29, 22, 24, 33,  1,  4,  3,  2,  1,  5,  3,  7,\n",
       "        11,  0],\n",
       "       [17, 21, 38,  1,  3,  4,  2,  1,  6,  6,  5, 11,  0,  0,  0,  0,\n",
       "         0,  0],\n",
       "       [19, 23, 35, 31, 22, 24, 33,  1,  3,  5,  2,  1,  4,  6,  6,  4,\n",
       "         0,  0],\n",
       "       [19, 23, 35, 31, 22, 24, 33,  1,  5, 11,  2,  1,  8,  4, 12, 11,\n",
       "         0,  0],\n",
       "       [18, 31, 37, 24, 29, 22, 24, 33,  1,  4, 11,  2,  1,  4,  7,  6,\n",
       "         3,  0],\n",
       "       [17, 21, 38,  1,  5, 12,  2,  1,  9, 10,  9,  5,  0,  0,  0,  0,\n",
       "         0,  0],\n",
       "       [19, 23, 35, 31, 22, 24, 33,  1,  5,  9,  2,  1,  4, 10,  8, 11,\n",
       "         0,  0],\n",
       "       [20, 24, 32, 35, 24, 29, 22, 24, 33,  1,  5, 11,  2,  1,  5,  7,\n",
       "         8,  3],\n",
       "       [13, 36, 25, 36, 34, 35,  1,  5, 12,  2,  1, 10,  5,  7,  5,  0,\n",
       "         0,  0],\n",
       "       [16, 21, 30, 36, 21, 33, 38,  1,  5,  4,  2,  1,  8, 10, 10,  4,\n",
       "         0,  0],\n",
       "       [19, 23, 35, 31, 22, 24, 33,  1,  6,  3,  2,  1,  5,  6,  4,  8,\n",
       "         0,  0],\n",
       "       [13, 32, 33, 27, 28,  1,  3, 10,  2,  1,  8, 11,  6, 11,  0,  0,\n",
       "         0,  0],\n",
       "       [13, 36, 25, 36, 34, 35,  1,  6,  4,  2,  1,  9, 10, 10,  3,  0,\n",
       "         0,  0]], dtype=int32)>"
      ]
     },
     "execution_count": 711,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "id": "6085570b-8fb8-4069-9db1-ed8b4e8dc3e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 10), dtype=int32, numpy=\n",
       "array([[ 3,  1,  8,  7, 11,  1,  8, 11,  1,  6],\n",
       "       [ 5, 10,  9,  3, 11,  1,  5, 11,  3,  8],\n",
       "       [ 8,  6,  8,  4, 11,  1,  6, 11,  3, 10],\n",
       "       [ 4,  3,  7,  8, 11,  1,  5, 11,  1,  2],\n",
       "       [ 7,  8, 10,  9, 11,  1,  5, 11,  3,  2],\n",
       "       [ 9,  2,  3,  5, 11,  2,  2, 11,  1,  5],\n",
       "       [ 3,  6,  5, 10, 11,  1,  4, 11,  1, 10],\n",
       "       [ 9,  1,  2,  1, 11,  1,  3, 11,  2,  6],\n",
       "       [ 9,  6,  9,  6, 11,  1,  3, 11,  1, 10],\n",
       "       [ 5,  6,  7,  2, 11,  1,  6, 11,  1,  5],\n",
       "       [ 6,  1,  5,  9, 11,  1,  6, 11,  1, 10],\n",
       "       [10,  6,  3,  8, 11,  1,  3, 11,  3,  7],\n",
       "       [ 9,  2, 10,  5, 11,  1,  2, 11,  3,  6],\n",
       "       [ 4,  3, 10,  7, 11,  1,  8, 11,  2,  8],\n",
       "       [ 7,  1,  4,  4, 11,  1, 10, 11,  1,  2],\n",
       "       [ 7,  3,  6,  5, 11,  1,  4, 11,  1,  8],\n",
       "       [ 2,  2,  9,  6, 11,  1,  7, 11,  1,  4],\n",
       "       [ 6,  6,  1,  4, 11,  1,  3, 11,  2,  4],\n",
       "       [ 6,  7,  2,  1, 11,  1,  5, 11,  1,  2],\n",
       "       [ 3,  1,  5,  9, 11,  2,  3, 11,  2,  1],\n",
       "       [ 4,  4,  3,  9, 11,  1,  6, 11,  1,  2],\n",
       "       [ 2,  4,  4,  2, 11,  2,  1, 11,  1,  3],\n",
       "       [ 6,  2, 10,  9, 11,  2,  1, 11,  3,  9],\n",
       "       [ 2,  5,  4,  1, 11,  2,  2, 11,  2,  9],\n",
       "       [ 7,  8,  7,  3, 11,  1,  6, 11,  3, 10],\n",
       "       [ 2,  8,  6,  9, 11,  2,  1, 11,  3,  7],\n",
       "       [ 3,  5,  6,  1, 11,  1, 10, 11,  3,  9],\n",
       "       [ 8,  3,  5,  3, 11,  1,  9, 11,  3, 10],\n",
       "       [ 6,  8,  8,  2, 11,  1,  2, 11,  3,  2],\n",
       "       [ 3,  4,  2,  6, 11,  2,  1, 11,  4,  1],\n",
       "       [ 6,  9,  4,  9, 11,  1,  5, 11,  1,  8],\n",
       "       [ 7,  8,  8,  1, 11,  1,  9, 11,  4,  2]], dtype=int32)>"
      ]
     },
     "execution_count": 712,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9ede24-6a44-49a4-91c9-4fd8802f8ed5",
   "metadata": {},
   "source": [
    "### Simple Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a64b89-93cc-4194-99c2-4cf543d5efd5",
   "metadata": {},
   "source": [
    "Let's first train a simple model that uses the most basic seq to seq architecture.\n",
    "- Encoder\n",
    "    - Embeds inputs\n",
    "    - GRU layer with one output\n",
    "- Repeat encoder's output to form seq of same length as target\n",
    "- Decoder\n",
    "    - GRU that outputs seq\n",
    "    - Dense softmax for each output of seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "6edb2773-036f-4722-95e4-89ede74807e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(INPUT_CHARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "36c8c556-9eab-415d-a086-7e301d1daeb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(OUTPUT_CHARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "5b148994-47e8-48b6-b625-6a8c0bf77dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 10])"
      ]
     },
     "execution_count": 620,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "c947a017-e839-4c2e-bd5a-7cb67e6bd2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 32\n",
    "input_dim = len(INPUT_CHARS) + 1         # padding is index 0\n",
    "output_dim = len(OUTPUT_CHARS) + 1       # padding is index 0\n",
    "\n",
    "encoder = keras.models.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=[None]),\n",
    "    keras.layers.Embedding(input_dim=input_dim, output_dim=embed_dim),\n",
    "    keras.layers.GRU(128) # outputs last output vector of size 128\n",
    "])\n",
    "\n",
    "decoder = keras.models.Sequential([\n",
    "    keras.layers.GRU(128, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(output_dim, activation=\"softmax\")),\n",
    "])\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    encoder,\n",
    "    keras.layers.RepeatVector(10), # must be equal to target string length\n",
    "    decoder\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "id": "b6262005-cd3e-4923-beb2-075840659cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Nadam(learning_rate=5e-5)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "id": "75d2c9d3-2b54-487f-9d1d-c8a6faa4d616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 15s 18ms/step - loss: 2.7435e-05 - accuracy: 1.0000 - val_loss: 1.9824e-05 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_set, epochs=1,\n",
    "                    validation_data=valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "id": "6d70c287-f95d-458a-9c01-46c3d1103023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 1s 5ms/step - loss: 2.9934e-05 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.9933540645288303e-05, 1.0]"
      ]
     },
     "execution_count": 635,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20443015-027f-4064-8087-cc494423bc60",
   "metadata": {},
   "source": [
    "heheheheh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "id": "b47f6062-0f36-40a1-92a5-1ff2494232da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 615ms/step\n"
     ]
    }
   ],
   "source": [
    "probas = model.predict(encode_date_strs([\"April 04, 2022\"], INPUT_CHARS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "id": "4bb7003a-1a24-41a0-ab08-1b9a44841bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10, 12)"
      ]
     },
     "execution_count": 683,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probas.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753620db-0e99-4362-8423-b2a4e51bf536",
   "metadata": {},
   "source": [
    "One element in batch, 10 chars, 12 possible probas for each char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "id": "b6fdd3b8-599f-4f69-9f9b-2c9f3e2ba715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10)"
      ]
     },
     "execution_count": 684,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = np.argmax(probas, axis=2)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "id": "3a2e0b9a-3595-4070-9e6c-6da2b65c4d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  1,  3,  3, 11,  1, 10, 11,  1,  5]])"
      ]
     },
     "execution_count": 685,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b63f109-f0f1-45a3-b471-637b84b3951b",
   "metadata": {},
   "source": [
    "One element in batch, 10 predicted chars according to max proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "id": "6e7796ed-9571-4662-afc3-7302bf8c99f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ids_to_date_strs(ids, chars=OUTPUT_CHARS):\n",
    "    return [\"\".join([(\"?\" + chars)[index] for index in sequence])\n",
    "            for sequence in ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "id": "1e7e450d-7a0f-46cf-b814-1f5c6fd0f852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2022-09-04']"
      ]
     },
     "execution_count": 690,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_to_date_strs(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379c39f5-66b5-4274-87c5-82424e9a5ab5",
   "metadata": {},
   "source": [
    "Oof it's wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "id": "90ddb2ac-d2ff-4cc1-a4ec-908513431602",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = encode_date_strs([\"September 17, 2009\", \"July 14, 1789\"], INPUT_CHARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "id": "7a4d2d1b-cd93-4f9e-8cde-a985796173b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "2009-09-17\n",
      "1789-07-14\n"
     ]
    }
   ],
   "source": [
    "ids = np.argmax(model.predict(X_new), axis=-1)\n",
    "for date_str in ids_to_date_strs(ids):\n",
    "    print(date_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "id": "d14f94a1-0db5-45f7-92db-5b340d50f132",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = 18\n",
    "\n",
    "def prepare_date_strs_padded(date_strs):\n",
    "    X = encode_date_strs(date_strs, INPUT_CHARS)\n",
    "    if X.shape[1] < max_input_length:\n",
    "        X = tf.pad(X, [[0, 0], [0, max_input_length - X.shape[1]]])\n",
    "    return X\n",
    "\n",
    "def convert_date_strs(date_strs):\n",
    "    X = prepare_date_strs_padded(date_strs)\n",
    "    #ids = model.predict_classes(X)\n",
    "    ids = np.argmax(model.predict(X), axis=-1)\n",
    "    return ids_to_date_strs(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "id": "489fd4ce-2fab-4820-8fda-60564970fcf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['2020-05-02', '1789-07-14']"
      ]
     },
     "execution_count": 696,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_date_strs([\"May 02, 2020\", \"July 14, 1789\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11c1c05-30fd-426d-9eed-88d216583a8a",
   "metadata": {},
   "source": [
    "### Encoder-Decoder w/ Teacher Forcing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b32ee2-cdb7-4f5e-8927-f91f06079fcb",
   "metadata": {},
   "source": [
    "Our previous model just repeated the encoder's output to form the decoder's input sequence, this is not optimal - let's use the previous target as the input instead (and during inference use the previous time step's prediction)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f5d2a0-1760-4655-9b24-ec7aa00f943f",
   "metadata": {},
   "source": [
    "Let's first use tensors, and we can adapt into a mappable function for dataset objects later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "id": "9cdb5f57-80b0-4714-a522-a4f7f77146d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = date_str_dataset(10000)\n",
    "X_valid, Y_valid = date_str_dataset(2000)\n",
    "X_test, Y_test = date_str_dataset(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "id": "3f6303a2-12d5-4c80-8fb4-78c6ed23e0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sos_id = len(OUTPUT_CHARS) + 1\n",
    "\n",
    "def shifted_output_sequences(Y):\n",
    "    sos_tokens = tf.fill(dims=(len(Y), 1), value=sos_id)\n",
    "    return tf.concat([sos_tokens, Y[:, :-1]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "id": "fff9609f-ddaa-4734-b7aa-3d171a7fba3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_decoder = shifted_output_sequences(Y_train)\n",
    "X_valid_decoder = shifted_output_sequences(Y_valid)\n",
    "X_test_decoder = shifted_output_sequences(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9728584-29df-43ba-bfe0-9d85a6c646ab",
   "metadata": {},
   "source": [
    "We do not need last char for the decoder input - we still have the last char in the target data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "id": "23a3e9a4-01ba-422d-8522-594798007cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_str_encoder_decoder_dataset(size):\n",
    "    X, Y = random_dates(size) # X (size, dtype=str), Y (size, dtype=str)\n",
    "    X_ids_padded = prepare_date_strs_padded(X)\n",
    "    Y_ids = encode_date_strs(Y, OUTPUT_CHARS)\n",
    "    Y_shifted = shifted_output_sequences(Y_ids)\n",
    "    \n",
    "    return (X_ids_padded, Y_shifted), Y_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "id": "a7298e79-ad6f-44e3-9b9d-1179216cbf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = tf.data.Dataset.from_tensor_slices(\n",
    "    date_str_encoder_decoder_dataset(10000)).shuffle(10000).batch(32).prefetch(1)\n",
    "\n",
    "valid_set = tf.data.Dataset.from_tensor_slices(date_str_encoder_decoder_dataset(2000)).batch(32).prefetch(1)\n",
    "test_set = tf.data.Dataset.from_tensor_slices(date_str_encoder_decoder_dataset(2000)).batch(32).prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b451edc4-337d-4119-ab6d-982e0b227ea7",
   "metadata": {},
   "source": [
    "Now let's bulid our encoder-decoder model that takes the previous step's target as input for decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "id": "7dfc9b5b-5b6d-4406-8b44-e5e8290ac028",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_embed_dim = 32\n",
    "decoder_embed_dim = 32\n",
    "n_gru_units = 128\n",
    "\n",
    "K.clear_session()\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "\n",
    "# encoder input: takes date str id seq\n",
    "encoder_input = keras.layers.Input(shape=[None], dtype=tf.int32)\n",
    "# encoder embed: embed seq id to meaningful vector\n",
    "encoder_embedding = keras.layers.Embedding(\n",
    "    input_dim=len(INPUT_CHARS) + 1, \n",
    "    output_dim=encoder_embed_dim)(encoder_input)\n",
    "# encoder\n",
    "encoder = keras.layers.GRU(n_gru_units, return_state=True)\n",
    "encoder_output, encoder_state_h = encoder(encoder_embedding)\n",
    "# encoder state (for LSTM this would be state_h and state_c)\n",
    "encoder_state = encoder_state_h\n",
    "\n",
    "\n",
    "# decoder input: takes shifted target id seq\n",
    "decoder_input = keras.layers.Input(shape=[None], dtype=tf.int32)\n",
    "# decoder embed: embed seq id to meaningful vector\n",
    "decoder_embedding = keras.layers.Embedding(\n",
    "    input_dim=len(OUTPUT_CHARS) + 2,\n",
    "    output_dim=decoder_embed_dim)(decoder_input)\n",
    "# decoder gru output\n",
    "decoder_gru_output = keras.layers.GRU(n_gru_units, return_sequences=True)(\n",
    "    decoder_embedding, initial_state=encoder_state)\n",
    "# final decoder proba output\n",
    "decoder_output = keras.layers.TimeDistributed(\n",
    "    keras.layers.Dense(len(OUTPUT_CHARS) + 1, activation=\"softmax\"))(decoder_gru_output)\n",
    "\n",
    "\n",
    "# model\n",
    "model = keras.models.Model(inputs=[encoder_input, decoder_input],\n",
    "                           outputs=[decoder_output])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ac83e6-b4b1-4bce-b798-33912faf5f60",
   "metadata": {},
   "source": [
    "Basically: encoder (input date str id seq) -> pass state to decoder -> decoder (shifted target id seq) -> output target id seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "id": "cd3493e4-5ab0-4840-a019-74e8f9cc381e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Nadam(learning_rate=5e-3)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "id": "f3006965-8ee0-4e80-b25f-6dc7bfec1bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "313/313 [==============================] - 9s 18ms/step - loss: 1.1362 - accuracy: 0.5633 - val_loss: 0.5468 - val_accuracy: 0.7740\n",
      "Epoch 2/20\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.4683 - accuracy: 0.7982 - val_loss: 0.3949 - val_accuracy: 0.8328\n",
      "Epoch 3/20\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.4119 - accuracy: 0.8269 - val_loss: 0.3579 - val_accuracy: 0.8499\n",
      "Epoch 4/20\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.3230 - accuracy: 0.8647 - val_loss: 0.3023 - val_accuracy: 0.8723\n",
      "Epoch 5/20\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.2925 - accuracy: 0.8817 - val_loss: 0.2500 - val_accuracy: 0.9034\n",
      "Epoch 6/20\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.2256 - accuracy: 0.9154 - val_loss: 0.1845 - val_accuracy: 0.9274\n",
      "Epoch 7/20\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.1459 - accuracy: 0.9426 - val_loss: 0.1106 - val_accuracy: 0.9568\n",
      "Epoch 8/20\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0533 - accuracy: 0.9805 - val_loss: 0.0965 - val_accuracy: 0.9724\n",
      "Epoch 9/20\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0208 - accuracy: 0.9941 - val_loss: 0.0315 - val_accuracy: 0.9910\n",
      "Epoch 10/20\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0152 - accuracy: 0.9958 - val_loss: 0.0049 - val_accuracy: 0.9986\n",
      "Epoch 11/20\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 0.0055 - val_accuracy: 0.9991\n",
      "Epoch 13/20\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 4.9301e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 2.8773e-04 - accuracy: 1.0000 - val_loss: 2.9336e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 1.8652e-04 - accuracy: 1.0000 - val_loss: 2.1154e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 1.3600e-04 - accuracy: 1.0000 - val_loss: 1.6158e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 1.0433e-04 - accuracy: 1.0000 - val_loss: 1.2732e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 8.2557e-05 - accuracy: 1.0000 - val_loss: 1.0287e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 6.6639e-05 - accuracy: 1.0000 - val_loss: 8.4803e-05 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 5.4541e-05 - accuracy: 1.0000 - val_loss: 7.0447e-05 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe787b09480>"
      ]
     },
     "execution_count": 811,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_set, epochs=20,\n",
    "          validation_data=valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "id": "b618178e-aafe-4da0-bdba-6dc56213e09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 5ms/step - loss: 1.1494e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.00011493735655676574, 1.0]"
      ]
     },
     "execution_count": 812,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ea1f66-ea1d-4e7d-b47c-1051fc2784e8",
   "metadata": {},
   "source": [
    "Great! Let's test it in action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "id": "4852565f-6813-4b12-b87d-5cf9c9370065",
   "metadata": {},
   "outputs": [],
   "source": [
    "sos_id = len(OUTPUT_CHARS) + 1\n",
    "max_output_length = 10\n",
    "\n",
    "def predict_date_strs(date_strs):\n",
    "    \"\"\"\n",
    "    Take a list of date strings like [\"July 14, 1789\", \"May 01, 2020\"] and \n",
    "    output their converted formats using our encoder-decoder model.\n",
    "    \n",
    "    Ex.\n",
    "    In:  predict_date_strs([\"July 14, 1789\", \"May 01, 2020\"])\n",
    "    Out: ['1789-07-14', '2020-05-01']\n",
    "    \"\"\"\n",
    "    \n",
    "    # get proper seq inputs for model\n",
    "    X = prepare_date_strs_padded(date_strs) # encoder input\n",
    "    Y_pred = tf.fill(dims=(len(date_strs), 1), value=sos_id) # decoder input non padded (one char at a time, starting with sos)\n",
    "    \n",
    "    # iterate till full prediction\n",
    "    for index in range(max_output_length):\n",
    "        # pad Y_pred with 0s till seq length\n",
    "        pad_size = max_output_length - Y_pred.shape[-1]\n",
    "        X_decoder = tf.pad(Y_pred, [[0, 0], [0, pad_size]])\n",
    "        Y_probas_next = model.predict((X, X_decoder), verbose=0)[:, index:index+1] # predicted char\n",
    "        Y_pred_next = tf.argmax(Y_probas_next, axis=-1, output_type=tf.int32) # get max out of 12 possibile chars\n",
    "        Y_pred = tf.concat([Y_pred, Y_pred_next], axis=-1)\n",
    "    return ids_to_date_strs(Y_pred[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "id": "521abac2-59f8-4b3e-99c8-c0494fc15715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1789-07-14', '2020-05-01']"
      ]
     },
     "execution_count": 837,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_date_strs([\"July 14, 1789\", \"May 01, 2020\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1b39a8-c80a-4315-9543-7d85b6ffafe1",
   "metadata": {},
   "source": [
    "Nice! Take it slow but fully understand things! That's the way to learn!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddffc83b-3377-423e-afe0-e2d193b18956",
   "metadata": {},
   "source": [
    "### Using tfa.seq2seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3298bf4f-d925-496d-ac75-c816d3a9acb7",
   "metadata": {},
   "source": [
    "The third implementation of encoder-decoder, let's use tensorflow-addon's seq2seq API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129b2cfd-2ae8-49eb-96cf-d8cc1130deb7",
   "metadata": {},
   "source": [
    "With the normal training sampler, there's really no differene btwn seq2seq and our above implementation using just Functional API. But if we use GreedyEmbeddingSampler, it will automatically use the argmax of the outputted probas as the input for the next time step. This will mean much easier inferencing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "id": "baad5c95-ab19-4284-85af-bf2cb8e1015d",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "encoder_embedding_size = 32\n",
    "decoder_embedding_size = 32\n",
    "units = 128\n",
    "\n",
    "\n",
    "# encoder\n",
    "encoder_inputs = keras.layers.Input(shape=[None], dtype=tf.int32)\n",
    "encoder_embeddings = keras.layers.Embedding(\n",
    "    len(INPUT_CHARS) + 1, encoder_embedding_size)(encoder_inputs)\n",
    "encoder = keras.layers.GRU(units, return_state=True)\n",
    "encoder_outputs, state_h = encoder(encoder_embeddings)\n",
    "encoder_state = [state_h]\n",
    "\n",
    "\n",
    "# greedy sampler\n",
    "decoder_embedding_layer = keras.layers.Embedding(\n",
    "    len(OUTPUT_CHARS) + 2, decoder_embedding_size)\n",
    "inference_sampler = tfa.seq2seq.sampler.GreedyEmbeddingSampler(\n",
    "    embedding_fn=decoder_embedding_layer)\n",
    "\n",
    "\n",
    "# decoder\n",
    "decoder_cell = keras.layers.GRUCell(units)\n",
    "output_layer = keras.layers.Dense(len(OUTPUT_CHARS) + 1)\n",
    "\n",
    "inference_decoder = tfa.seq2seq.basic_decoder.BasicDecoder(\n",
    "    decoder_cell, inference_sampler, output_layer=output_layer,\n",
    "    maximum_iterations=max_output_length) # set max iter to prevent infinite loop if decoder never outputs end token\n",
    "\n",
    "batch_size = tf.shape(encoder_inputs)[:1]\n",
    "start_tokens = tf.fill(dims=batch_size, value=sos_id) # need start tokens for decoder\n",
    "\n",
    "final_outputs, final_state, final_sequence_lengths = inference_decoder(\n",
    "    start_tokens,\n",
    "    initial_state=encoder_state,\n",
    "    start_tokens=start_tokens,\n",
    "    end_token=0)\n",
    "Y_proba = keras.layers.Activation(\"softmax\")(final_outputs.rnn_output)\n",
    "\n",
    "\n",
    "# model\n",
    "model = keras.models.Model(inputs=[encoder_inputs], # only need encoder inputs now\n",
    "                                     outputs=[Y_proba]) # automatically outputs the id instead of probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "id": "9ba8a016-0d60-44fb-907c-675f78d8c4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Nadam(learning_rate=5e-3)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "                        optimizer=optimizer,\n",
    "                        metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432f85b8-553d-46f5-888a-51befdd0153c",
   "metadata": {},
   "source": [
    "Since we don't need the shifted decoder inputs, let's use the data from the first model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "id": "8743c85a-8b5f-4bd3-b307-510818333750",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = tf.data.Dataset.from_tensor_slices(date_str_dataset(10000)).shuffle(10000).batch(32).prefetch(1)\n",
    "valid_set = tf.data.Dataset.from_tensor_slices(date_str_dataset(2000)).batch(32).prefetch(1)\n",
    "test_set = tf.data.Dataset.from_tensor_slices(date_str_dataset(2000)).batch(32).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "id": "ebda73a8-de0d-430b-b820-5554b1fbfbf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "313/313 [==============================] - 9s 18ms/step - loss: 1.3558 - accuracy: 0.5054 - val_loss: 1.2891 - val_accuracy: 0.5839\n",
      "Epoch 2/20\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.5512 - accuracy: 0.7786 - val_loss: 0.4532 - val_accuracy: 0.8125\n",
      "Epoch 3/20\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.3874 - accuracy: 0.8358 - val_loss: 0.3636 - val_accuracy: 0.8475\n",
      "Epoch 4/20\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.3634 - accuracy: 0.8441 - val_loss: 0.3608 - val_accuracy: 0.8482\n",
      "Epoch 5/20\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.3155 - accuracy: 0.8681 - val_loss: 0.2463 - val_accuracy: 0.8979\n",
      "Epoch 6/20\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.1750 - accuracy: 0.9213 - val_loss: 0.1099 - val_accuracy: 0.9490\n",
      "Epoch 7/20\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.0736 - accuracy: 0.9720 - val_loss: 0.0233 - val_accuracy: 0.9936\n",
      "Epoch 8/20\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.0220 - accuracy: 0.9941 - val_loss: 0.0072 - val_accuracy: 0.9990\n",
      "Epoch 9/20\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.0027 - accuracy: 0.9998 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 8.9402e-04 - accuracy: 1.0000 - val_loss: 7.5758e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 5.4475e-04 - accuracy: 1.0000 - val_loss: 5.1071e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 3.7393e-04 - accuracy: 1.0000 - val_loss: 3.6703e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 2.7279e-04 - accuracy: 1.0000 - val_loss: 2.7909e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 2.0699e-04 - accuracy: 1.0000 - val_loss: 2.1533e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 1.6090e-04 - accuracy: 1.0000 - val_loss: 1.7044e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 1.2701e-04 - accuracy: 1.0000 - val_loss: 1.3615e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 1.0161e-04 - accuracy: 1.0000 - val_loss: 1.1025e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 8.2191e-05 - accuracy: 1.0000 - val_loss: 9.0255e-05 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 6.6995e-05 - accuracy: 1.0000 - val_loss: 7.4128e-05 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 5.4976e-05 - accuracy: 1.0000 - val_loss: 6.1407e-05 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe78efef5e0>"
      ]
     },
     "execution_count": 861,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_set, epochs=20,\n",
    "                    validation_data=valid_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f920db-bb1d-4d54-8b55-3dac5ca0936a",
   "metadata": {},
   "source": [
    "Now that we've trained the model, we can make a model reusing the trained encoder and decoder that only outputs the ids instead of probas. And, now we can directly pass the preprocessed date strings instead of having to create a shifted decoder input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "id": "0a0e958a-079e-4c64-8bcb-50e1b5203a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_model = keras.models.Model(inputs=[encoder_inputs],\n",
    "                                     outputs=[final_outputs.sample_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "id": "2cea3022-2251-4f7c-9873-d887a6c096cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['2022-08-02']"
      ]
     },
     "execution_count": 865,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_to_date_strs(inference_model.predict(prepare_date_strs_padded([\"August 02, 2022\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "id": "3899dcef-3ac8-4eb9-9403-00bb5d3baee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_predict_date_strs(date_strs):\n",
    "    X = prepare_date_strs_padded(date_strs)\n",
    "    Y_pred = inference_model.predict(X, verbose=0)\n",
    "    return ids_to_date_strs(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "id": "13008fe6-89c8-4e27-8c57-e5b5c7e8aefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 ms ± 3.38 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit fast_predict_date_strs([\"July 14, 1789\", \"May 01, 2020\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a326cc-6a03-4265-bce5-c4161b723f52",
   "metadata": {},
   "source": [
    "There are many more versions:\n",
    "- Train with encodre and decoder datasets (encoder is just input, decoder is target shifted right by one using sos)\n",
    "    - Use scheduled sampler, can change proba of using predicted output instead of decoder input\n",
    "- Inference using Sample Sampler\n",
    "    - Like greedy, but has a temperature arg that allows for random choosing of output instead of argmax\n",
    "- Using keras subclassing API and attention wrapper that takes in all encoder_outputs instead of just last encoder state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd34e14-3d5f-41a5-a190-a3a57d08f3ce",
   "metadata": {},
   "source": [
    "## Using Pretrained Model to Generate Shakespearean Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa441d13-a944-4dab-9ca7-a7287d1bf8ef",
   "metadata": {},
   "source": [
    "From huggingface's transformers library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "id": "7e2a779e-d806-42df-a61e-35e8555852cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "177af3b4d0f4439c9bf7e7c227f85fe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/656 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "206db120a8ee44fb866ae756c88dca75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/445M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFOpenAIGPTLMHeadModel.\n",
      "\n",
      "All the layers of TFOpenAIGPTLMHeadModel were initialized from the model checkpoint at openai-gpt.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFOpenAIGPTLMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFOpenAIGPTLMHeadModel\n",
    "\n",
    "model = TFOpenAIGPTLMHeadModel.from_pretrained(\"openai-gpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902a569c-1dbc-4f4c-80da-08756b91475f",
   "metadata": {},
   "source": [
    "Now we need a tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "id": "a24a83cc-fe0e-4f27-b940-504d57f86c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "193d2902188a4ccc93d961a3bc4264e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/797k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d6fce18a0ca460a91e1f4088377ad12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/448k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n"
     ]
    }
   ],
   "source": [
    "from transformers import OpenAIGPTTokenizer\n",
    "\n",
    "tokenizer = OpenAIGPTTokenizer.from_pretrained(\"openai-gpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4108275-ce88-49f0-876a-17643daef4a0",
   "metadata": {},
   "source": [
    "Let's use the tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "id": "acaa21d3-4a81-4838-b34a-500fab77fab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=int32, numpy=\n",
       "array([[  616,  5751,  6404,   498,  9606,   240,   616, 26271,  7428,\n",
       "        16187]], dtype=int32)>"
      ]
     },
     "execution_count": 874,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_text = \"This royal throne of kings, this sceptred isle\"\n",
    "encoded_prompt = tokenizer.encode(prompt_text,\n",
    "                                  add_special_tokens=False,\n",
    "                                  return_tensors=\"tf\")\n",
    "encoded_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe5ab04-b8a6-411b-93b9-ef1b3c27013b",
   "metadata": {},
   "source": [
    "Using the prompt text and model, let's generate text!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "id": "05b24167-235f-4f82-b98d-d3e9ff729a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 50), dtype=int32, numpy=\n",
       "array([[  616,  5751,  6404,   498,  9606,   240,   616, 26271,  7428,\n",
       "        16187,   240,   246,  6404,   498,  1109,   481,   618,   488,\n",
       "          481,  3016,   488,   240,  1855,   240,   246,  4206,   522,\n",
       "          246,  4206,   498,   481,  4187,   240,   566,   498,  1076,\n",
       "         2609,  1643,   260,  1734,  8777,   617,   984,   481,  2313,\n",
       "          498,   481, 39145, 30675,   762],\n",
       "       [  616,  5751,  6404,   498,  9606,   240,   616, 26271,  7428,\n",
       "        16187,   980,   694, 28981,   500,   481,  6073,   498,   704,\n",
       "        23376,   239, 40477,   597,   921,   704,  5176,   488,  1357,\n",
       "          481,  1807,   239,  1370,   562,  6384,   617,   481,   566,\n",
       "          512,  4978,   557,   618,   239, 40477,   600,  5298,   557,\n",
       "          600,  1172,   481,  1002,   239],\n",
       "       [  616,  5751,  6404,   498,  9606,   240,   616, 26271,  7428,\n",
       "        16187,   239,   580,  2227,   485,   921,   531,  3367,   500,\n",
       "          524,  3997,   260,   507,   544,  3344,   500,   481, 12624,\n",
       "          498,   481,  2811,   239,   851,   481, 20356, 34334,   488,\n",
       "          481, 20356, 34334,   921,   246,  9611,  3367,   500,   704,\n",
       "         3997,   557,   862,   239,  3955],\n",
       "       [  616,  5751,  6404,   498,  9606,   240,   616, 26271,  7428,\n",
       "        16187,   485,   580,  1958,   556, 11514,   525,   759,   580,\n",
       "         1684,   702,   481,  1581,   498,  3543,   239, 40477,   244,\n",
       "          618,   509,   520,   500,  8037,   257,   244, 40477,   244,\n",
       "        11857,   240,   244,   481,  1177,  1617,  2163,   240,   524,\n",
       "          756,  3299,   239, 40477,   244],\n",
       "       [  616,  5751,  6404,   498,  9606,   240,   616, 26271,  7428,\n",
       "        16187,   812,   580,   524,  8205,   239,   244, 40477,   244,\n",
       "         1598,   524,  6230,   240, 24693,   240,   244,   603,  1930,\n",
       "          613,   556,  1424,  7684,   240,   244,   587,   595,   580,\n",
       "         5624,   240,   562,   481,  1469,  2821,  2494,   510,   239,\n",
       "          244, 40477,   244,   664,  3491]], dtype=int32)>"
      ]
     },
     "execution_count": 875,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_sequences = 5\n",
    "length = 40\n",
    "\n",
    "generated_sequences = model.generate(\n",
    "    input_ids=encoded_prompt,\n",
    "    do_sample=True,\n",
    "    max_length=length + len(encoded_prompt[0]),\n",
    "    temperature=1.0,\n",
    "    top_k=0,\n",
    "    top_p=0.9,\n",
    "    repetition_penalty=1.0,\n",
    "    num_return_sequences=num_sequences,\n",
    ")\n",
    "\n",
    "generated_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "id": "4d49dbd9-9809-49a9-a34f-5a43ad9d3f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this royal throne of kings, this sceptred isle, a throne of both the king and the queen and, perhaps, a castle or a castle of the gods, one of those tall five - story levels from which the nose of the mightiest man\n",
      "--------------------------------------------------------------------------------\n",
      "this royal throne of kings, this sceptred isle has been diluted in the minds of your communities. \n",
      " now take your sisters and leave the city. call for aid from the one you claim as king. \n",
      " they fled as they heard the voice.\n",
      "--------------------------------------------------------------------------------\n",
      "this royal throne of kings, this sceptred isle. be certain to take an interest in his staff - it is hidden in the rubble of the dam. let the asturians and the asturians take a cautious interest in your staff as well. otherwise\n",
      "--------------------------------------------------------------------------------\n",
      "this royal throne of kings, this sceptred isle to be filled with bronze that can be caught by the fire of storm. \n",
      " \" king was she in chains? \" \n",
      " \" sire, \" the courser answered, his head lowered. \n",
      " \"\n",
      "--------------------------------------------------------------------------------\n",
      "this royal throne of kings, this sceptred isle will be his destiny. \" \n",
      " \" may his enemies, beware, \" said welter with great dread, \" do not be feared, for the dead shall follow me. \" \n",
      " \" no indeed\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for sequence in generated_sequences:\n",
    "    text = tokenizer.decode(sequence, clean_up_tokenization_spaces=True)\n",
    "    print(text)\n",
    "    print(\"-\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
