{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f98ad507-9cdc-4d04-b6d1-4fa68f0d3dc2",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "348eb39c-8555-4652-8b59-6ba4107f63a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle math and data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import math\n",
    "\n",
    "# to plot nice figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# handle files\n",
    "import os\n",
    "import sys\n",
    "import joblib\n",
    "\n",
    "# hash table classes\n",
    "from collections import Counter\n",
    "\n",
    "# output\n",
    "import tqdm\n",
    "\n",
    "# deep learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f07a85-17c4-4eba-9515-37523448213b",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9870dc1-220d-4e89-a895-4c6ac23c9d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 69\n",
    "\n",
    "K = keras.backend\n",
    "\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "\n",
    "def reset_backend():\n",
    "    K.clear_session()\n",
    "    np.random.seed(SEED)\n",
    "    tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa39cc2-73d0-4e43-bab2-37484e6d9da3",
   "metadata": {},
   "source": [
    "# Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921b2a26-9c7d-4936-82d0-61efae09143f",
   "metadata": {},
   "source": [
    "## Generate Shakespearean Text With Character RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3965b13-b6d5-455f-b527-2ad74bffcd7a",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13880873-8739-4de1-9f9a-808efed0884d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://homl.info/shakespeare\n",
      "1115394/1115394 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "DOWNLOAD_URL = \"https://homl.info/shakespeare\"\n",
    "filepath = keras.utils.get_file(\"shakespeare.txt\", DOWNLOAD_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37e8d25e-7dc2-4191-b5c9-bc35f664c09f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/calvinhuang/.keras/datasets/shakespeare.txt'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d870c763-2c78-4d54-98be-7121a2961e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filepath) as f:\n",
    "    shakespeare_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a33e8ba3-878b-426c-9fd9-7808b74e1045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115394"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(shakespeare_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d273bda-dedd-4965-a7c2-fc21cfbbc224",
   "metadata": {},
   "source": [
    "Over 1 million characters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360ca349-3a73-4ded-9ab5-61c91928704b",
   "metadata": {},
   "source": [
    "Let's encode our text, basically char to indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51556d70-279a-4969-a851-3f72f1033ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(shakespeare_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235a7a63-67f5-467d-8e07-cae66e4a10bb",
   "metadata": {},
   "source": [
    "Now we can use the tokenizer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015e8864-85b2-4824-9386-016388af0f5b",
   "metadata": {},
   "source": [
    "Wrap the text in a list, because the method by default will convert each text in the given `texts`. Which means if you just pass the string, it will convert each character to its own sequence and you will have a list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "675aac52-46cf-42e2-8de1-aff7350b78c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[7, 6, 31, 1, 15, 16, 1, 10, 5, 15, 2, 1, 6, 8, 1, 19, 5, 12, 26, 6, 10, 31, 11]]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences([\"Hi! My name is Calvin!\\n\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a6d6f58e-417f-4cec-b45f-a2ff4f2a9eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['h i !   m y   n a m e   i s   c a l v i n ! \\n']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sequences_to_texts([[7, 6, 31, 1, 15, 16, 1, 10, 5, 15, 2, 1, 6, 8, 1, 19, 5, 12, 26, 6, 10, 31, 11]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "27008d75-cba8-4cb4-aa60-78fcbf320066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 1,\n",
       " 'e': 2,\n",
       " 't': 3,\n",
       " 'o': 4,\n",
       " 'a': 5,\n",
       " 'i': 6,\n",
       " 'h': 7,\n",
       " 's': 8,\n",
       " 'r': 9,\n",
       " 'n': 10,\n",
       " '\\n': 11,\n",
       " 'l': 12,\n",
       " 'd': 13,\n",
       " 'u': 14,\n",
       " 'm': 15,\n",
       " 'y': 16,\n",
       " 'w': 17,\n",
       " ',': 18,\n",
       " 'c': 19,\n",
       " 'f': 20,\n",
       " 'g': 21,\n",
       " 'b': 22,\n",
       " 'p': 23,\n",
       " ':': 24,\n",
       " 'k': 25,\n",
       " 'v': 26,\n",
       " '.': 27,\n",
       " \"'\": 28,\n",
       " ';': 29,\n",
       " '?': 30,\n",
       " '!': 31,\n",
       " '-': 32,\n",
       " 'j': 33,\n",
       " 'q': 34,\n",
       " 'x': 35,\n",
       " 'z': 36,\n",
       " '3': 37,\n",
       " '&': 38,\n",
       " '$': 39}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ed7426bc-b797-4ed7-9c73-03e1a0eaef4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_id = len(tokenizer.word_index)\n",
    "max_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "174ad237-8600-432b-8cb8-0a716cc9188e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115394"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_size = tokenizer.document_count\n",
    "dataset_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52848de1-d9e4-47b8-b00a-9e16d93794c3",
   "metadata": {},
   "source": [
    "So the tokenizer can be fit to text and it will create a word_index hashtable aka dict for each char or word. Then you can easily map texts to sequences and vice versa. Let's create our encoded data now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8800d66-9fe3-4d10-9e8b-cc8b1f76bb11",
   "metadata": {},
   "source": [
    "Subtract by 1 so that our enocded indices will be from 0 to 38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8411488c-fb95-45b6-8683-bcc6bd3098c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "[encoded] = np.array(tokenizer.texts_to_sequences([shakespeare_text])) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "335072b1-8ba5-497f-bcca-500954da44fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1115394,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7a6b250a-b112-46db-8301-87ea4a03d854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428f6fdd-a71a-4059-9949-2d52e0f0aeda",
   "metadata": {},
   "source": [
    "Now let's create our efficient datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8957c99e-3d71-4cb5-8739-1dc2d10f35f8",
   "metadata": {},
   "source": [
    "### Create Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad552073-02d7-4c43-a482-d8430b65b891",
   "metadata": {},
   "source": [
    "- Set train set to first 90% of text\n",
    "- Create dataset with windows of 100 characters\n",
    "    - Window size of 101 because target is next char\n",
    "- Flat map with batch on windows\n",
    "- Shuffle\n",
    "- Batch datset\n",
    "- Split input and target data\n",
    "- Apply one hot encoding to inputs\n",
    "- Prefetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "82fe3a66-e2c5-4c61-a843-f0b3b05e390c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1003854"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = dataset_size * 90 // 100\n",
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "94ba8499-22bc-4dbb-a39d-106a35c65230",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dcecd7-276b-401a-b46b-6297efdf5d97",
   "metadata": {},
   "source": [
    "Now let's get windows of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e8d60d95-5821-4b45-a430-6a8340ae0f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 100\n",
    "window_length = n_steps + 1\n",
    "dataset = dataset.window(window_length, shift=1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0c2c1c-eba6-4f70-8f1c-b706605b37e2",
   "metadata": {},
   "source": [
    "This creates a dataset of window datasets (yes each window is a dataset). To get just one dataset and convert windows to tensors, we need to use `flat_map` and batch each window to it's own size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "327c07ae-d340-477b-8c9c-9105c3db3c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.flat_map(lambda window: window.batch(window_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54154750-72ab-420e-bafc-8fb0aa710b9a",
   "metadata": {},
   "source": [
    "Now let's shuffle our windows and then batch them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8f9c6775-25c9-448a-83c0-1896920e0b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "dataset = dataset.shuffle(10000).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6a4b22-bcee-4fda-a0d0-8890a2d309f1",
   "metadata": {},
   "source": [
    "Let's split our data into input and target sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e905b1f4-7851-4c6f-aeb0-ffed54ebafe9",
   "metadata": {},
   "source": [
    "Shape of our data: `(batch_size, 101)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e2f5f3b2-506f-4e60-94a4-18b7833c43b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855d5de3-1520-4a82-890a-3d3b43346a06",
   "metadata": {},
   "source": [
    "Now let's apply one hot to our inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40be0ff6-1366-425e-8344-7bbf32881be2",
   "metadata": {},
   "source": [
    "Shape of our data: `(input (batch_size, 100, 1), target (batch_size, 100, 1))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cc12a895-2bc5-46c2-8703-f47dad55db9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda X_batch, Y_batch:\n",
    "                          (tf.one_hot(X_batch, max_id), Y_batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4620815d-7234-4954-b468-6551d7270bd7",
   "metadata": {},
   "source": [
    "Finally, let's prefetch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "909f7f5d-db8a-404d-bc29-30675a272113",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2945943-5522-41ef-9e05-74f5ef91cec3",
   "metadata": {},
   "source": [
    "### Model Arch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b1129d-ad2a-41ca-ba46-4c12e506208d",
   "metadata": {},
   "source": [
    "Let's use two GRU layers with 128 units each for long term memory. Add 20% dropout to both inputs and hidden states to prevent unstable gradients since this model will run through 100 steps or 100 layers when unrolled (which is pretty deep). Finally, we have a timedistributed dense layer (which means it will output for every step, not just last output) that will output 39 probabilities for the 39 possible characters using a softmax activation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a15136-e8a5-45b8-997d-f0c7f5573377",
   "metadata": {},
   "source": [
    "- 2 GRU layers, 128 units, 20% dropout\n",
    "- Dense layer, 39 units, softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1ff7d2-e480-493e-afe6-da920958ed1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id],\n",
    "                     dropout=0.2, recurrent_dropout=0.2),\n",
    "    keras.layers.GRU(128, return_sequences=True,\n",
    "                     dropout=0.2, recurrent_dropout=0.2),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(max_id, \n",
    "                                                    activation=\"softmax\"))\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cc1a7f-bf2f-4b88-a67e-aea1b3d3c1bb",
   "metadata": {},
   "source": [
    "This model takes way too long to train, let's use a stateful model and just copy the weights over."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48b27fb-8cf6-496b-9f77-246716575934",
   "metadata": {},
   "source": [
    "### Stateful Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92eb5c6d-8700-4f05-8082-4c4715f94aba",
   "metadata": {},
   "source": [
    "Stateful means copying the last hidden state of the previous iteration over to the new iteration instead of using 0s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530edf07-9d2c-4688-ab0c-b1f9b54ca9b5",
   "metadata": {},
   "source": [
    "To do this we will need our batches to be consecutive, an easy way is to have batches of size 1. Also our windows will need to have a shift of n_steps (not n_steps + 1 since we only add 1 for the outputs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e229f137-ff06-410e-aad9-d532d09d9d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(None, None, 39), dtype=tf.float32, name=None), TensorSpec(shape=(None, None), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])\n",
    "dataset = dataset.window(window_length, shift=n_steps, drop_remainder=True)\n",
    "dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
    "dataset = dataset.batch(1) # no shuffle and batch of size 1\n",
    "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:])) # batches are just one window\n",
    "dataset = dataset.map(lambda X_batch, Y_batch: \n",
    "                      (tf.one_hot(X_batch, max_id), Y_batch)) # again, batches are just one window\n",
    "dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85186c7c-808d-4609-b50b-7010a497af80",
   "metadata": {},
   "source": [
    "But then we won't be able to take advantage of vectorization performance improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd7ecf3-7484-4e1f-a9ce-44792ef058fc",
   "metadata": {},
   "source": [
    "So, let's do this:\n",
    "- Split our data into 32 chunks in order\n",
    "- Window each dataset\n",
    "- Stack the datasets\n",
    "    - Each element should be a (32, 101) tensor\n",
    "    - The first element is the first 101 steps or first window of the 32 datasets\n",
    "    - No need to batch now, since it's already in batch shape after stacking\n",
    "- Split input and target\n",
    "- Apply one hot \n",
    "- Prefetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6eb2c90a-e777-4fbe-bfd8-5913ceb49594",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "encoded_parts = np.array_split(encoded[:train_size], batch_size)\n",
    "datasets = []\n",
    "for encoded_part in encoded_parts:\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(encoded_part)\n",
    "    dataset = dataset.window(window_length, shift=n_steps, drop_remainder=True)\n",
    "    dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
    "    datasets.append(dataset)\n",
    "dataset = tf.data.Dataset.zip(tuple(datasets)).map(lambda *windows: tf.stack(windows))\n",
    "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n",
    "dataset = dataset.map(\n",
    "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))\n",
    "dataset = dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fad3e50-8074-448d-87a8-f17104d831e4",
   "metadata": {},
   "source": [
    "Now let's train our model - we need to set stateful to True for our RNN layers. Also, we need to make sure to reset the state between epochs (because we don't want to have bias from previous epochs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b7e6ff49-71f8-48e9-ad90-7a65710234af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(128, batch_input_shape=[batch_size, None, max_id], \n",
    "                     return_sequences=True, stateful=True, \n",
    "                     dropout=0.2, recurrent_dropout=0.2),\n",
    "    keras.layers.GRU(128, \n",
    "                     return_sequences=True, stateful=True, \n",
    "                     dropout=0.2, recurrent_dropout=0.2),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(max_id, \n",
    "                                                    activation=\"softmax\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "207199c3-3128-49b3-a9d8-8303ec02afb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru (GRU)                   (32, None, 128)           64896     \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (32, None, 128)           99072     \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (32, None, 39)           5031      \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 168,999\n",
      "Trainable params: 168,999\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c130769d-0093-4233-bd9f-e27b93229ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "313/313 [==============================] - 37s 108ms/step - loss: 2.5950 - accuracy: 0.2640\n",
      "Epoch 2/50\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 2.2225 - accuracy: 0.3486\n",
      "Epoch 3/50\n",
      "313/313 [==============================] - 35s 112ms/step - loss: 2.2374 - accuracy: 0.3464\n",
      "Epoch 4/50\n",
      "313/313 [==============================] - 33s 105ms/step - loss: 2.3146 - accuracy: 0.3284\n",
      "Epoch 5/50\n",
      "313/313 [==============================] - 33s 106ms/step - loss: 1.9202 - accuracy: 0.4258\n",
      "Epoch 6/50\n",
      "313/313 [==============================] - 33s 105ms/step - loss: 1.8669 - accuracy: 0.4409\n",
      "Epoch 7/50\n",
      "313/313 [==============================] - 32s 102ms/step - loss: 1.8276 - accuracy: 0.4509\n",
      "Epoch 8/50\n",
      "313/313 [==============================] - 32s 104ms/step - loss: 1.7973 - accuracy: 0.4590\n",
      "Epoch 9/50\n",
      "313/313 [==============================] - 32s 101ms/step - loss: 1.7740 - accuracy: 0.4650\n",
      "Epoch 10/50\n",
      "313/313 [==============================] - 31s 100ms/step - loss: 1.7526 - accuracy: 0.4700\n",
      "Epoch 11/50\n",
      "313/313 [==============================] - 32s 101ms/step - loss: 1.7722 - accuracy: 0.4654\n",
      "Epoch 12/50\n",
      "313/313 [==============================] - 32s 102ms/step - loss: 1.7828 - accuracy: 0.4632\n",
      "Epoch 13/50\n",
      "313/313 [==============================] - 32s 102ms/step - loss: 1.7581 - accuracy: 0.4699\n",
      "Epoch 14/50\n",
      "313/313 [==============================] - 32s 101ms/step - loss: 1.8498 - accuracy: 0.4466\n",
      "Epoch 15/50\n",
      "313/313 [==============================] - 31s 100ms/step - loss: 1.7950 - accuracy: 0.4599\n",
      "Epoch 16/50\n",
      "313/313 [==============================] - 32s 101ms/step - loss: 1.7586 - accuracy: 0.4689\n",
      "Epoch 17/50\n",
      "313/313 [==============================] - 32s 101ms/step - loss: 1.8569 - accuracy: 0.4434\n",
      "Epoch 18/50\n",
      "313/313 [==============================] - 32s 103ms/step - loss: 1.8825 - accuracy: 0.4365\n",
      "Epoch 19/50\n",
      "313/313 [==============================] - 32s 101ms/step - loss: 1.8468 - accuracy: 0.4452\n",
      "Epoch 20/50\n",
      "313/313 [==============================] - 32s 102ms/step - loss: 1.7277 - accuracy: 0.4767\n",
      "Epoch 21/50\n",
      "313/313 [==============================] - 32s 101ms/step - loss: 1.6997 - accuracy: 0.4835\n",
      "Epoch 22/50\n",
      "313/313 [==============================] - 32s 101ms/step - loss: 1.6554 - accuracy: 0.4954\n",
      "Epoch 23/50\n",
      "313/313 [==============================] - 32s 102ms/step - loss: 1.6461 - accuracy: 0.4976\n",
      "Epoch 24/50\n",
      "313/313 [==============================] - 32s 101ms/step - loss: 1.6401 - accuracy: 0.4994\n",
      "Epoch 25/50\n",
      "313/313 [==============================] - 32s 102ms/step - loss: 1.6339 - accuracy: 0.5009\n",
      "Epoch 26/50\n",
      "313/313 [==============================] - 32s 101ms/step - loss: 1.6291 - accuracy: 0.5024\n",
      "Epoch 27/50\n",
      "313/313 [==============================] - 33s 104ms/step - loss: 1.6238 - accuracy: 0.5037\n",
      "Epoch 28/50\n",
      "313/313 [==============================] - 33s 104ms/step - loss: 1.6201 - accuracy: 0.5045\n",
      "Epoch 29/50\n",
      "313/313 [==============================] - 33s 104ms/step - loss: 1.6152 - accuracy: 0.5055\n",
      "Epoch 30/50\n",
      "313/313 [==============================] - 32s 102ms/step - loss: 1.6100 - accuracy: 0.5070\n",
      "Epoch 31/50\n",
      "313/313 [==============================] - 32s 102ms/step - loss: 1.6066 - accuracy: 0.5081\n",
      "Epoch 32/50\n",
      "313/313 [==============================] - 32s 101ms/step - loss: 1.6038 - accuracy: 0.5091\n",
      "Epoch 33/50\n",
      "313/313 [==============================] - 32s 102ms/step - loss: 1.6003 - accuracy: 0.5097\n",
      "Epoch 34/50\n",
      "313/313 [==============================] - 32s 102ms/step - loss: 1.5968 - accuracy: 0.5106\n",
      "Epoch 35/50\n",
      "313/313 [==============================] - 32s 102ms/step - loss: 1.5941 - accuracy: 0.5109\n",
      "Epoch 36/50\n",
      "313/313 [==============================] - 32s 102ms/step - loss: 1.5909 - accuracy: 0.5118\n",
      "Epoch 37/50\n",
      "313/313 [==============================] - 33s 104ms/step - loss: 1.5884 - accuracy: 0.5128\n",
      "Epoch 38/50\n",
      "313/313 [==============================] - 32s 102ms/step - loss: 1.5860 - accuracy: 0.5131\n",
      "Epoch 39/50\n",
      "313/313 [==============================] - 32s 104ms/step - loss: 1.5827 - accuracy: 0.5145\n",
      "Epoch 40/50\n",
      "313/313 [==============================] - 33s 105ms/step - loss: 1.5806 - accuracy: 0.5147\n",
      "Epoch 41/50\n",
      "313/313 [==============================] - 33s 105ms/step - loss: 1.5781 - accuracy: 0.5154\n",
      "Epoch 42/50\n",
      "313/313 [==============================] - 33s 106ms/step - loss: 1.5764 - accuracy: 0.5159\n",
      "Epoch 43/50\n",
      "313/313 [==============================] - 33s 105ms/step - loss: 1.5747 - accuracy: 0.5168\n",
      "Epoch 44/50\n",
      "313/313 [==============================] - 33s 106ms/step - loss: 1.5715 - accuracy: 0.5174\n",
      "Epoch 45/50\n",
      "313/313 [==============================] - 35s 110ms/step - loss: 1.5703 - accuracy: 0.5170\n",
      "Epoch 46/50\n",
      "313/313 [==============================] - 34s 109ms/step - loss: 1.5670 - accuracy: 0.5177\n",
      "Epoch 47/50\n",
      "313/313 [==============================] - 33s 106ms/step - loss: 1.5675 - accuracy: 0.5181\n",
      "Epoch 48/50\n",
      "313/313 [==============================] - 33s 106ms/step - loss: 1.5643 - accuracy: 0.5188\n",
      "Epoch 49/50\n",
      "313/313 [==============================] - 33s 105ms/step - loss: 1.5624 - accuracy: 0.5195\n",
      "Epoch 50/50\n",
      "313/313 [==============================] - 34s 108ms/step - loss: 1.5611 - accuracy: 0.5194\n"
     ]
    }
   ],
   "source": [
    "# reset states between epochs\n",
    "class ResetStatesCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_begin(self, epoch, logs):\n",
    "        self.model.reset_states()\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(dataset, epochs=50,\n",
    "                    callbacks=[ResetStatesCallback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d53c77d-a2ad-4825-8b13-18c9d7309ca3",
   "metadata": {},
   "source": [
    "After training this, let's now save the weights and copy to the stateless model (so we can predict on batches of any size, not just 32)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "666036bf-cae5-41b0-8175-393c9c72f4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR = os.path.join(\".\", \"_models\", \"15_nlp\")\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "model.save_weights(os.path.join(SAVE_DIR, \"shakespeare_rnn_weights.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fe176b0d-911b-4940-b3ca-c39ba0d0460d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id],\n",
    "                     dropout=0.2, recurrent_dropout=0.2),\n",
    "    keras.layers.GRU(128, return_sequences=True,\n",
    "                     dropout=0.2, recurrent_dropout=0.2),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(max_id, \n",
    "                                                    activation=\"softmax\"))\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "048715a3-c437-4bfd-8a5d-a9cdfb1eb387",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(os.path.join(SAVE_DIR, \"shakespeare_rnn_weights.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58c3993-4fa0-486f-b382-07e51fd4a204",
   "metadata": {},
   "source": [
    "### Generate Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227b27f3-d3e0-498b-83e4-5ee03be748ac",
   "metadata": {},
   "source": [
    "To generate new shakespearean text:\n",
    "- Preprocess input text\n",
    "    - text to seq encode, subtract 1 from indices, to one hot\n",
    "- Predict next char probas\n",
    "- Randomly select a char using probas\n",
    "    - Add a temperature var to control how much variability you want\n",
    "- Convert selected char index to char\n",
    "    - Add 1, seq to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f41a57c8-e7b8-44ca-8534-3c17a9e91a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    encoded_text = np.array(tokenizer.texts_to_sequences([text]))\n",
    "    return tf.one_hot(encoded_text - 1, max_id)\n",
    "\n",
    "def next_char(model, text, temperature):\n",
    "    X_new = preprocess(text)\n",
    "    y_proba = model.predict(X_new, verbose=0)[0, -1:, :] # first batch, last step's output (aka last char), all probas\n",
    "    rescaled_logits = tf.math.log(y_proba) / temperature\n",
    "    char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\n",
    "    return tokenizer.sequences_to_texts(char_id.numpy())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e33b3f1-fbed-4a17-962d-3142a5b205c0",
   "metadata": {},
   "source": [
    "Now let's create a function that generates `n_chars` chars of shakespearean text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b2cd7865-1d08-4f69-942c-c2fdf053fe11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shakespearean_text(model, seed_text, n_chars=50, temperature=1):\n",
    "    text = seed_text\n",
    "    for _ in range(n_chars):\n",
    "        text += next_char(model, text, temperature)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8aa6b0e-9268-4d55-adae-91fdec7159fc",
   "metadata": {},
   "source": [
    "Let's try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f7ff667b-f502-40f8-8c83-a3edf0c75a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ter:\n",
      "the seem the contraction of the court of the c\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"t\"\n",
    "print(shakespearean_text(model, seed_text, temperature=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e51a0f9c-adeb-4fd6-8f2e-d48f409f851e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t, bear for the\n",
      "good more one with your triar:\n",
      "nor,\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"t\"\n",
    "print(shakespearean_text(model, seed_text, temperature=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a64583f6-3559-41f0-b733-9baaf5443a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t, ly yearss, margand?\n",
      "ty-murr incewertess, kness y\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"t\"\n",
    "print(shakespearean_text(model, seed_text, temperature=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b106a4e-591d-4649-a08f-c6b5b48bb7d6",
   "metadata": {},
   "source": [
    "Cool! Let's try using a longer seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8eeb39ed-7c20-4671-aa14-592b311b09a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamlet said thou are\n",
      "since to serve go alive a timplint of such gentlemans,\n",
      "the suition warwick. then!\n",
      "him thou best one thy fortune one hisband.\n",
      "\n",
      "all:\n",
      "i will go should being give my cieizen's or thou\n",
      "so cursed wife with a a.---\n",
      "\n",
      "bygy:\n",
      "aid you had be rather, our conession that?\n",
      "\n",
      "sicinius:\n",
      "ha, sheve i horse of a lunious\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"Hamlet said thou are\"\n",
    "print(shakespearean_text(model, seed_text, n_chars=300, temperature=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bcc8fa-4181-4597-b034-d1dfbe82b361",
   "metadata": {},
   "source": [
    "## IMDB Review Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a733ddf-0d96-4078-a86d-ea664a71a033",
   "metadata": {},
   "source": [
    "### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e74aa6bc-2dfa-4c2a-b223-1ca533cc05dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets, info = tfds.load(\"imdb_reviews\", as_supervised=True, with_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a38c125b-7bc7-4ff2-adfc-892a13f9d0a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Split('train'): <SplitInfo num_examples=25000, num_shards=1>,\n",
       " Split('test'): <SplitInfo num_examples=25000, num_shards=1>,\n",
       " Split('unsupervised'): <SplitInfo num_examples=50000, num_shards=1>}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info.splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c4d9ee02-5126-4d93-8348-7d4cfd9b15ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = info.splits[\"train\"].num_examples\n",
    "train_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f3d7c7-61b4-4544-b893-3a08d6f9bb10",
   "metadata": {},
   "source": [
    "Let's look at what the input data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3bea98a6-19fb-4be4-a419-2f50cbddb0db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <PrefetchDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
       " 'test': <PrefetchDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
       " 'unsupervised': <PrefetchDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "cf3f94ce-fada-43b2-871c-67f10a8a84eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "5f606e9a-0d9f-4fd4-b821-35c58897581a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'In this film we have the fabulous opportunity to see what happened to Timon and Pumbaa in the film when they are not shown - which is a lot! This film even goes back to before Simba and (presumbably) just after the birth of Kiara. <br /><br />Quite true to the first film, \"Lion King 1/2 (or Lion King 3 in other places)\" is a funny, entertaining, exciting and surprising film (or sequel if that\\'s what you want to call it). A bundle of surprises and hilarity await for you!<br /><br />While Timon and Pumbaa are watching a film at the cinema (with a remote control), Timon and Pumbaa have an argument of what point of \"The Lion King\" they are going to start watching, as Timon wants to go to the part when he and Pumbaa come in and Pumbaa wants to go back to the beginning. They have a very fair compromise of watching the film of their own story, which is what awaits... It starts with Timon\\'s first home...<br /><br />For anyone with a good sense of humour who liked the first films of just about any age, enjoy \"Lion King 1/2\"! :-)'>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for x, y in dataset.take(100).shuffle(100):\n",
    "    pass\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9814f1ce-cfb7-49bb-9218-d89514a236fe",
   "metadata": {},
   "source": [
    "We need to preprocess the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "dceb39b2-4435-4426-8124-39e655c8f01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(X_batch, y_batch):\n",
    "    X_batch = tf.strings.substr(X_batch, 0, 300) # truncate every review to first 300 chars\n",
    "    X_batch = tf.strings.regex_replace(X_batch, b\"<br\\\\s*/?>\", b\" \") # replace <br /> with whitespace\n",
    "    X_batch = tf.strings.regex_replace(X_batch, b\"[^a-zA-Z']\", b\" \") # replace anything that is not a-z, A-Z, or ' \n",
    "                                                                     # with whitespace\n",
    "    X_batch = tf.strings.split(X_batch) # create a sequence of words split by whitespace\n",
    "    return X_batch.to_tensor(default_value=b\"<pad>\"), y_batch # pad uneven ragged tensor so that we will have a dense tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779085f3-0c03-4f64-a93e-fb7b1e37452d",
   "metadata": {},
   "source": [
    "Now let's encode the words to ids\n",
    "- Create a vocabulary w/ Counter\n",
    "- Create a lookup table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cb6b11-b565-4371-8fb4-7f903960b177",
   "metadata": {},
   "source": [
    "Create a vocabulary in descending order most common to least common words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "bd203fab-9d61-4c6c-8580-484c26e1d12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "vocabulary = Counter()\n",
    "for X_batch, y_batch in dataset.batch(batch_size).map(preprocess):\n",
    "    for review in X_batch:\n",
    "        vocabulary.update(list(review.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "76125d69-727b-432e-a078-0d4d94cae19d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(b'<pad>', 214309),\n",
       " (b'the', 61137),\n",
       " (b'a', 38564),\n",
       " (b'of', 33983),\n",
       " (b'and', 33431)]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary.most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b40173-d1e2-462b-bfaa-1a5bfd1b37ee",
   "metadata": {},
   "source": [
    "Looks about right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "4744daa8-bdea-4668-adb1-8545e9c93f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53893"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "9e3afd7a-b8d6-44d1-b632-a3ecdf5e5721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(b'Legion', 7),\n",
       " (b'Republic', 7),\n",
       " (b'Cassie', 7),\n",
       " (b'hallucinations', 7),\n",
       " (b'Clinton', 7)]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary.most_common(10005)[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4b880c-9f77-4596-812c-833691a4317a",
   "metadata": {},
   "source": [
    "Let's just use the 10000 most common and use 1000 oov buckets for any other possible characters (probably don't even need 1000 since each sequence is only 300 words max)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "8d00c7b1-fb65-49e7-88f2-7e79d5d74c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "truncated_vocabulary = [word for word, count in vocabulary.most_common(vocab_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "c24f52fd-275b-437f-8b3a-a8173f50ec22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(truncated_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "d5a167d9-2710-411e-b7a4-70010a50c63d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'<pad>', b'the', b'a', b'of', b'and']"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truncated_vocabulary[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc061a92-6ecd-450c-bda1-88968e12b804",
   "metadata": {},
   "source": [
    "Create a lookup table initializer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "7f1b66a7-566c-47bb-81c4-320aa52c0612",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = tf.constant(truncated_vocabulary)\n",
    "word_ids = tf.range(len(truncated_vocabulary), dtype=tf.int64)\n",
    "vocab_init = tf.lookup.KeyValueTensorInitializer(words, word_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4090d967-fade-43c1-bf24-d3d6f3f44c7b",
   "metadata": {},
   "source": [
    "Create a lookup table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "527efd99-e61b-4941-9f46-a9f54855cdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_oov_buckets = 1000\n",
    "table = tf.lookup.StaticVocabularyTable(vocab_init, num_oov_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "173c0b2e-f959-4da1-8a47-aae69dd98d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 8), dtype=int64, numpy=array([[   22,    12,  1488,   175, 10716,  1831,   167,     0]])>"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = tf.constant([b\"This movie sucks real fucking ass man <pad>\".split()])\n",
    "table.lookup(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2794d3fa-b9e9-4977-9bfc-466bf96d407f",
   "metadata": {},
   "source": [
    "Now let's map the lookup table to each input sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "2577f4cb-1eb7-487c-a653-a65b8f312c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_words(X_batch, y_batch):\n",
    "    return table.lookup(X_batch), y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fb0114-58f7-4621-984c-4ef1743d9c7a",
   "metadata": {},
   "source": [
    "### Create Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f69d71-290f-46f3-bb8f-f0a6f6952833",
   "metadata": {},
   "source": [
    "Now let's wrap everything up together\n",
    "- Shuffle data\n",
    "- Batch the data\n",
    "- Preprocess text\n",
    "- Encode words\n",
    "- Prefetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "e3143e00-26ed-4156-bb14-a21d1a83362c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test = tfds.load(\"imdb_reviews\", as_supervised=True, split=[\"train\", \"test[:50%]\", \"test[50%:]\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "75622545-57fa-43dd-8ed7-68aeccb17d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_set = train.shuffle(10000).batch(batch_size).map(preprocess).map(encode_words).prefetch(1)\n",
    "valid_set = valid.batch(batch_size).map(preprocess).map(encode_words).prefetch(1)\n",
    "test_set = test.batch(batch_size).map(preprocess).map(encode_words).prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8673ee4b-5a8a-44ab-abd1-19efb4d3dfa6",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3d29bf-cf44-4e17-b49b-ad5a2f5590a0",
   "metadata": {},
   "source": [
    "We need to embed our word sequences for the model to learn good patterns and fast.\n",
    "- Input (batch_size, seq_length)\n",
    "- Embed (batch_size, seq_length, embed_dimen)\n",
    "- GRU\n",
    "- GRU\n",
    "- Dense Binary final output only (batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "fcc634f8-5a09-4fe3-b1f3-f4001ed0f3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dimen = 128\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Embedding(vocab_size + num_oov_buckets, \n",
    "                          embed_dimen, input_shape=[None]),\n",
    "    keras.layers.Conv1D(filters=embed_dimen, kernel_size=2, strides=2),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.GRU(128, return_sequences=True, \n",
    "                     dropout=0.2, recurrent_dropout=0.2),\n",
    "    keras.layers.GRU(128, \n",
    "                     dropout=0.2, recurrent_dropout=0.2),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "791e0308-cbe0-4d02-86c8-e5fb3935005a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "f3869047-71d0-440c-b557-f177b59eca55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 53s 62ms/step - loss: 0.5647 - accuracy: 0.6964\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 50s 64ms/step - loss: 0.3691 - accuracy: 0.8373\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 49s 63ms/step - loss: 0.2288 - accuracy: 0.9086\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 49s 62ms/step - loss: 0.1298 - accuracy: 0.9524\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 48s 62ms/step - loss: 0.0761 - accuracy: 0.9731\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe7f926bf40>"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_set, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "a4e8eca9-4318-4045-b7fc-e20faf6f0ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 9s 10ms/step - loss: 1.0188 - accuracy: 0.7404\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.018828272819519, 0.7404000163078308]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacffeb3-a9b0-40fd-8ed7-c8ff0822a403",
   "metadata": {},
   "source": [
    "Seems like it overfit. Let's use masks to get rid of padding from the learning process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f73239-9f3b-4991-8665-6fac9a9add52",
   "metadata": {},
   "source": [
    "### Model Masking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296c35b0-326c-4f5b-a0d5-aa8f91e1315f",
   "metadata": {},
   "source": [
    "Using a mask to omit input values that equal 0, (id 0 is `<pad>`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "e66ea5bb-8c97-4496-8ecd-88e35ebf4972",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.layers.Input(shape=[None])\n",
    "mask = keras.layers.Lambda(lambda inputs: K.not_equal(inputs, 0))(inputs) # returns True for all non zero inputs\n",
    "z = keras.layers.Embedding(vocab_size + num_oov_buckets, embed_dimen)(inputs)\n",
    "z = keras.layers.GRU(128, return_sequences=True)(z, mask=mask)\n",
    "z = keras.layers.GRU(128)(z, mask=mask)\n",
    "outputs = keras.layers.Dense(1, activation=\"sigmoid\")(z)\n",
    "model = keras.Model(inputs=[inputs], outputs=[outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "9cb9f9b5-8708-40a8-b058-e8ef83bbfe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d803d9cb-6a25-473d-b552-031591f15790",
   "metadata": {},
   "source": [
    "Let's add tensorboard callback for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "55762143-1445-45ba-9706-94803d00a122",
   "metadata": {},
   "outputs": [],
   "source": [
    "TENSORBOARD_DIR = os.path.join(\".\", \"_tf_logs\", \"15_nlp\")\n",
    "os.makedirs(TENSORBOARD_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "f0f4f5f5-579f-4408-873e-fa606858e39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./_tf_logs/15_nlp/imdb_masked_model_run_00001\n"
     ]
    }
   ],
   "source": [
    "run_index = 1\n",
    "run_logdir = os.path.join(TENSORBOARD_DIR, \"imdb_masked_model_run_{:05d}\".format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(log_dir=run_logdir, embeddings_freq=10)\n",
    "print(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "e20072d2-b5dd-4df7-be90-e84e928468a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=5)\n",
    "lr_scheduler_cb = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "15d98de4-cb21-4942-921e-162e1a23b727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 82s 96ms/step - loss: 0.5569 - accuracy: 0.7042 - val_loss: 0.4925 - val_accuracy: 0.7590 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 69s 88ms/step - loss: 0.3775 - accuracy: 0.8358 - val_loss: 0.4883 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 0.2726 - accuracy: 0.8907 - val_loss: 0.5749 - val_accuracy: 0.7567 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 0.1348 - accuracy: 0.9521 - val_loss: 0.8755 - val_accuracy: 0.7502 - lr: 5.0000e-04\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 72s 92ms/step - loss: 0.0601 - accuracy: 0.9823 - val_loss: 1.0464 - val_accuracy: 0.7469 - lr: 2.5000e-04\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 69s 89ms/step - loss: 0.0301 - accuracy: 0.9933 - val_loss: 1.2488 - val_accuracy: 0.7455 - lr: 1.2500e-04\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 69s 88ms/step - loss: 0.0202 - accuracy: 0.9962 - val_loss: 1.3038 - val_accuracy: 0.7438 - lr: 6.2500e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe7f8db1450>"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_set, epochs=10,\n",
    "          validation_data=valid_set,\n",
    "          callbacks=[tensorboard_cb, early_stopping_cb, lr_scheduler_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0c522c-95c1-4ecc-adb5-935f11687dc0",
   "metadata": {},
   "source": [
    "Using tensorboard, we can visualize the closest embeddings to the two words below. Let's see what words their neighbors are!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "f3285c85-4ad7-43cf-8e03-9ca0bd535566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int64, numpy=array([438, 260])>"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_words = tf.constant([\"amazing\", \"awful\"])\n",
    "table.lookup(sample_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "c23c2ac1-d057-4de5-8dfb-79c1a2340bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100 closest neighbors including amazing itself\n",
    "amazing_neighbor_ids = [438,674,332,327,269,284,325,1498,813,93,687,107,1573,2719,1291,577,902,870,1921,751,68,783,10126,2304,2197,2554,3101,1238,1015,3369,2474,7271,5496,2811,592,2440,2756,3093,1744,142,3530,2830,849,5639,434,6034,3925,3665,2463,2359,335,3454,1172,6188,4264,376,3762,1982,8960,8737,1196,3977,1597,276,1519,10035,2489,2169,1124,3051,4542,2772,2672,1166,579,1499,5808,1030,3350,2821,6080,2075,1040,4482,1542,3559,2931,3173,5640,4556,1618,7308,2137,3792,6371,8059,8326,9408,695,5392,3180]\n",
    "\n",
    "# 100 closest neighbors including awful itself\n",
    "awful_neighbor_ids = [260,143,1044,302,396,981,731,313,420,450,1069,1256,388,1572,788,2503,972,1669,1724,537,2893,631,966,623,1329,1619,908,3175,2523,2912,2786,460,2149,2261,1488,1129,749,391,988,1927,221,514,498,1339,3829,2841,1882,853,633,1200,1361,1052,10838,4227,1657,4736,8873,3082,2364,1037,2530,1701,1184,5948,5242,1022,1814,2232,2500,3886,2386,2621,3116,624,3512,880,1702,805,4708,1464,5311,728,1666,2736,3599,961,4834,6331,2130,5558,1065,2920,493,4003,5134,2432,356,3305,3730,5277,8640]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6113b00c-9365-41c7-ac76-9a7f5353b42d",
   "metadata": {},
   "source": [
    "Now let's see what words they are!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "f87fcba6-f4fb-4117-917b-bd8718addcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazing_neighbors = [str(truncated_vocabulary[id_]) for id_ in amazing_neighbor_ids if id_ < 10000]\n",
    "awful_neighbors = [str(truncated_vocabulary[id_]) for id_ in awful_neighbor_ids if id_ < 10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "8feb36b1-bdde-478e-9295-449b4881cc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'amazing'           b'awful'\n",
      "b'fantastic'         b'worst'\n",
      "b'favorite'          b'pathetic'\n",
      "b'wonderful'         b'terrible'\n",
      "b'excellent'         b'worse'\n",
      "b'loved'             b'fails'\n",
      "b'enjoyed'           b'poorly'\n",
      "b'underrated'        b'boring'\n",
      "b'unique'            b'horrible'\n",
      "b'best'              b'waste'\n",
      "b'enjoyable'         b'dumb'\n",
      "b'love'              b'laughable'\n",
      "b'wonderfully'       b'stupid'\n",
      "b'extraordinary'     b'unfunny'\n",
      "b'touching'          b'weak'\n",
      "b'simple'            b'tedious'\n",
      "b'awesome'           b'disappointment'\n",
      "b'Great'             b'bottom'\n",
      "b'feelings'          b'promising'\n",
      "b'masterpiece'       b'crap'\n",
      "b'great'             b'WORST'\n",
      "b'superb'            b'Unfortunately'\n",
      "b'refreshing'        b'mess'\n",
      "b'Excellent'         b'ridiculous'\n",
      "b'captured'          b'redeeming'\n",
      "b'Wonderful'         b'lacks'\n",
      "b'plenty'            b'badly'\n",
      "b'funniest'          b'stinker'\n",
      "b'stellar'           b'Worst'\n",
      "b'friendship'        b'turkey'\n",
      "b'limitations'       b'idiotic'\n",
      "b'advanced'          b'disappointed'\n",
      "b\"today's\"           b'atrocious'\n",
      "b'hilarious'         b'ruined'\n",
      "b'hooked'            b'sucks'\n",
      "b'Dirty'             b'pointless'\n",
      "b'subtitles'         b'dull'\n",
      "b'soul'              b'poor'\n",
      "b'still'             b'wasted'\n",
      "b'timeless'          b'wooden'\n",
      "b'Bourne'            b'minutes'\n",
      "b'animated'          b'supposed'\n",
      "b'Pushing'           b'problem'\n",
      "b'perfect'           b'excuse'\n",
      "b'Twice'             b'flop'\n",
      "b'Novak'             b'Seagal'\n",
      "b'unforgettable'     b'hype'\n",
      "b'Nancy'             b'cover'\n",
      "b'Matthau'           b'predictable'\n",
      "b'together'          b'unbelievable'\n",
      "b'soccer'            b'painful'\n",
      "b'beautifully'       b'writers'\n",
      "b'Trey'              b'ignorant'\n",
      "b'Holes'             b'pretentious'\n",
      "b'enjoy'             b'tripe'\n",
      "b'Ramones'           b'REVIEW'\n",
      "b'Jackie'            b'unwatchable'\n",
      "b'teller'            b'Seriously'\n",
      "b'Finch'             b'unfortunately'\n",
      "b'knowing'           b'remotely'\n",
      "b'Gerard'            b'confused'\n",
      "b'singing'           b'producers'\n",
      "b'performance'       b'unintentional'\n",
      "b'unusual'           b'skits'\n",
      "b'Carrey'            b'total'\n",
      "b'packed'            b'pile'\n",
      "b'genius'            b'MST'\n",
      "b'stylish'           b'amateurish'\n",
      "b'widow'             b'abysmal'\n",
      "b'complicated'       b'offensive'\n",
      "b'pleased'           b'Terrible'\n",
      "b'surprisingly'      b'werewolf'\n",
      "b'heart'             b'bunch'\n",
      "b'pleasure'          b'Uwe'\n",
      "b'Antwone'           b'Is'\n",
      "b'gem'               b'crappy'\n",
      "b'Elvira'            b'falls'\n",
      "b'Ralph'             b'hurts'\n",
      "b'Haines'            b'scientist'\n",
      "b'Emma'              b'wastes'\n",
      "b'overall'           b'lame'\n",
      "b'Paulie'            b'okay'\n",
      "b'journey'           b'vampires'\n",
      "b'attitude'          b'Otherwise'\n",
      "b'stays'             b'joke'\n",
      "b'flawless'          b'security'\n",
      "b'Daisies'           b'stupidest'\n",
      "b'Lily'              b'suck'\n",
      "b'scared'            b'eager'\n",
      "b'Suspense'          b'Bad'\n",
      "b'baseball'          b'irritating'\n",
      "b'profound'          b'let'\n",
      "b'Dressed'           b'intention'\n",
      "b'lighter'           b'atrocity'\n",
      "b'blends'            b'titles'\n",
      "b'embezzler'         b'money'\n",
      "b'highly'            b'Dolph'\n",
      "b'Thailand'          b'downhill'\n",
      "b'Rings'             b'unoriginal'\n"
     ]
    }
   ],
   "source": [
    "for amazing_neighbor, awful_neighbor in zip(amazing_neighbors, awful_neighbors):\n",
    "    print(\"{:20} {}\".format(amazing_neighbor, awful_neighbor))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03878b0-f7f1-4175-a6e9-f879c9539cdd",
   "metadata": {},
   "source": [
    "Wow, embeddings really do work!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e43af23-df1a-4fd7-9605-d02509500cea",
   "metadata": {},
   "source": [
    "### Pretrained Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90922a51-0c1f-4830-91a0-75eebd6323cf",
   "metadata": {},
   "source": [
    "Let's use Google's pretrained model for english sentence embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1287aa32-bce6-49b1-841d-d1c171d3c97d",
   "metadata": {},
   "source": [
    "This model does not require preprocessing, so let's create new datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "7ad1abdf-8943-465d-8d2a-3371583b59b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test = tfds.load(\"imdb_reviews\", as_supervised=True, \n",
    "                               split=[\"train+test[:50%]\", \"test[50%:75%]\", \"test[75%:]\"])\n",
    "\n",
    "batch_size = 32\n",
    "train_set = train.shuffle(10000).batch(batch_size).prefetch(1)\n",
    "valid_set = valid.batch(batch_size).prefetch(1)\n",
    "test_set = test.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0ec95d-eccc-41b4-9af6-8d43f837aab1",
   "metadata": {},
   "source": [
    "Now let's create our model using the tfhub model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "8a394442-6762-40dc-9f01-d899c7275b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TFHUB_CACHE_DIR\"] = os.path.join(\".\", \"my_tfhub_cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "1a4a0ed0-84d7-40e6-b98a-ff14a0422f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/nnlm-en-dim50/1\", output_shape=[50],\n",
    "                   input_shape=[], dtype=tf.string),\n",
    "    keras.layers.Dense(150, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "3c644ccf-775b-4257-9a30-cbb91d3d8766",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "43345c27-fc7a-491e-b157-9b3ce8ab7307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1172/1172 [==============================] - 6s 4ms/step - loss: 0.5538 - accuracy: 0.7198 - val_loss: 0.5285 - val_accuracy: 0.7402\n",
      "Epoch 2/5\n",
      "1172/1172 [==============================] - 4s 3ms/step - loss: 0.5259 - accuracy: 0.7393 - val_loss: 0.5220 - val_accuracy: 0.7470\n",
      "Epoch 3/5\n",
      "1172/1172 [==============================] - 4s 3ms/step - loss: 0.5201 - accuracy: 0.7456 - val_loss: 0.5104 - val_accuracy: 0.7491\n",
      "Epoch 4/5\n",
      "1172/1172 [==============================] - 4s 3ms/step - loss: 0.5165 - accuracy: 0.7462 - val_loss: 0.5126 - val_accuracy: 0.7507\n",
      "Epoch 5/5\n",
      "1172/1172 [==============================] - 4s 3ms/step - loss: 0.5140 - accuracy: 0.7477 - val_loss: 0.5543 - val_accuracy: 0.7232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe7dc6d7940>"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_set, epochs=5,\n",
    "          validation_data=valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "56e6b194-69d2-40e6-a3f8-56762d604c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "dd95f382-baab-4a6c-b6f1-ea8295cf7200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./_tf_logs/15_nlp/imdb_tfhub_model_run_00006\n"
     ]
    }
   ],
   "source": [
    "run_index = 6\n",
    "run_logdir = os.path.join(TENSORBOARD_DIR, \"imdb_tfhub_model_run_{:05d}\".format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(log_dir=run_logdir, embeddings_freq=2)\n",
    "print(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "e1f0c1dd-1487-4621-9c94-5c33544a17ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10)\n",
    "lr_scheduler_cb = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "8a721ef2-b900-46b5-82cc-250a5c269102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.5129 - accuracy: 0.7501 - val_loss: 0.5192 - val_accuracy: 0.7498 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "1172/1172 [==============================] - 4s 3ms/step - loss: 0.5115 - accuracy: 0.7498 - val_loss: 0.5135 - val_accuracy: 0.7514 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.5101 - accuracy: 0.7516 - val_loss: 0.5100 - val_accuracy: 0.7504 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "1172/1172 [==============================] - 4s 3ms/step - loss: 0.5080 - accuracy: 0.7519 - val_loss: 0.5195 - val_accuracy: 0.7443 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.5074 - accuracy: 0.7530 - val_loss: 0.5140 - val_accuracy: 0.7477 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "1172/1172 [==============================] - 4s 3ms/step - loss: 0.5025 - accuracy: 0.7535 - val_loss: 0.5072 - val_accuracy: 0.7525 - lr: 5.0000e-04\n",
      "Epoch 7/100\n",
      "1172/1172 [==============================] - 4s 4ms/step - loss: 0.5016 - accuracy: 0.7569 - val_loss: 0.5080 - val_accuracy: 0.7549 - lr: 5.0000e-04\n",
      "Epoch 8/100\n",
      "1172/1172 [==============================] - 4s 3ms/step - loss: 0.5012 - accuracy: 0.7574 - val_loss: 0.5081 - val_accuracy: 0.7534 - lr: 5.0000e-04\n",
      "Epoch 9/100\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.4962 - accuracy: 0.7601 - val_loss: 0.5066 - val_accuracy: 0.7544 - lr: 2.5000e-04\n",
      "Epoch 10/100\n",
      "1172/1172 [==============================] - 4s 3ms/step - loss: 0.4953 - accuracy: 0.7604 - val_loss: 0.5083 - val_accuracy: 0.7515 - lr: 2.5000e-04\n",
      "Epoch 11/100\n",
      "1172/1172 [==============================] - 4s 4ms/step - loss: 0.4936 - accuracy: 0.7598 - val_loss: 0.5076 - val_accuracy: 0.7536 - lr: 2.5000e-04\n",
      "Epoch 12/100\n",
      "1172/1172 [==============================] - 4s 3ms/step - loss: 0.4933 - accuracy: 0.7634 - val_loss: 0.5082 - val_accuracy: 0.7544 - lr: 1.2500e-04\n",
      "Epoch 13/100\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.4918 - accuracy: 0.7624 - val_loss: 0.5063 - val_accuracy: 0.7565 - lr: 1.2500e-04\n",
      "Epoch 14/100\n",
      "1172/1172 [==============================] - 4s 3ms/step - loss: 0.4904 - accuracy: 0.7643 - val_loss: 0.5077 - val_accuracy: 0.7542 - lr: 1.2500e-04\n",
      "Epoch 15/100\n",
      "1172/1172 [==============================] - 4s 4ms/step - loss: 0.4890 - accuracy: 0.7648 - val_loss: 0.5068 - val_accuracy: 0.7558 - lr: 1.2500e-04\n",
      "Epoch 16/100\n",
      "1172/1172 [==============================] - 4s 3ms/step - loss: 0.4892 - accuracy: 0.7665 - val_loss: 0.5056 - val_accuracy: 0.7560 - lr: 6.2500e-05\n",
      "Epoch 17/100\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.4882 - accuracy: 0.7655 - val_loss: 0.5063 - val_accuracy: 0.7549 - lr: 6.2500e-05\n",
      "Epoch 18/100\n",
      "1172/1172 [==============================] - 4s 3ms/step - loss: 0.4884 - accuracy: 0.7628 - val_loss: 0.5065 - val_accuracy: 0.7542 - lr: 6.2500e-05\n",
      "Epoch 19/100\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.4869 - accuracy: 0.7648 - val_loss: 0.5085 - val_accuracy: 0.7541 - lr: 3.1250e-05\n",
      "Epoch 20/100\n",
      "1172/1172 [==============================] - 4s 3ms/step - loss: 0.4859 - accuracy: 0.7660 - val_loss: 0.5086 - val_accuracy: 0.7531 - lr: 3.1250e-05\n",
      "Epoch 21/100\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.4868 - accuracy: 0.7650 - val_loss: 0.5070 - val_accuracy: 0.7566 - lr: 1.5625e-05\n",
      "Epoch 22/100\n",
      "1172/1172 [==============================] - 4s 3ms/step - loss: 0.4851 - accuracy: 0.7654 - val_loss: 0.5057 - val_accuracy: 0.7557 - lr: 1.5625e-05\n",
      "Epoch 23/100\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.4856 - accuracy: 0.7678 - val_loss: 0.5077 - val_accuracy: 0.7542 - lr: 7.8125e-06\n",
      "Epoch 24/100\n",
      "1172/1172 [==============================] - 4s 3ms/step - loss: 0.4867 - accuracy: 0.7666 - val_loss: 0.5069 - val_accuracy: 0.7534 - lr: 7.8125e-06\n",
      "Epoch 25/100\n",
      "1172/1172 [==============================] - 5s 4ms/step - loss: 0.4856 - accuracy: 0.7654 - val_loss: 0.5076 - val_accuracy: 0.7563 - lr: 3.9063e-06\n",
      "Epoch 26/100\n",
      "1172/1172 [==============================] - 4s 4ms/step - loss: 0.4857 - accuracy: 0.7674 - val_loss: 0.5065 - val_accuracy: 0.7550 - lr: 3.9063e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe8054888b0>"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_set, epochs=100,\n",
    "          validation_data=valid_set,\n",
    "          callbacks=[tensorboard_cb, early_stopping_cb, lr_scheduler_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f8c2ef-ee7d-412b-bfbc-8a0239fffa0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
