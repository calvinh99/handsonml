{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a32de1bf-c68c-4771-979d-5ebc64bb8fc0",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebbf4722-0332-4797-a175-d1bf2594a557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "%pprint off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59a6188e-3595-4332-a3eb-17aa97a7ccd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(iris.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c564875-8070-41da-91fa-6d652465f306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes = iris[\"feature_names\"]\n",
    "attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee16ee9-012f-43ff-a9a6-f89f0f73d3f2",
   "metadata": {},
   "source": [
    "So we have 4 features all in centimeters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91b25479-4a2c-407c-82d7-e1c6bc35607c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = iris[\"target_names\"]\n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ae414d-0a4c-4a77-b9c9-0233a45c4230",
   "metadata": {},
   "source": [
    "These are the classes in order 0, 1, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8603cb8-e9a5-4090-926f-88b992514491",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris[\"data\"]\n",
    "\n",
    "y = iris[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e91c1fcc-4466-42c3-8a3c-53b008433e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541526b5-0ace-4d5c-8087-e43c06011414",
   "metadata": {},
   "source": [
    "## Add X<sub>0</sub> to X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e99484ff-6f0b-43f3-9870-e0a44c9dedaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.c_[np.ones((X.shape[0], 1)), X]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3251de6f-4ec4-4b62-8fdf-5cafa084ace0",
   "metadata": {},
   "source": [
    "Let's also define our number of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c8bc34b5-20b9-4dd1-8e86-0a4547793a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = np.unique(y).shape[0]\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf11756d-b9c5-4790-8705-d8215a9d3a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1. , 5.1, 3.5, 1.4, 0.2],\n",
       "       [1. , 4.9, 3. , 1.4, 0.2],\n",
       "       [1. , 4.7, 3.2, 1.3, 0.2]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "576b967e-562f-4dee-a3ac-f6a955a0863e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), array([50, 50, 50]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e66484c-505b-498a-b9ae-e9be40e6c3e9",
   "metadata": {},
   "source": [
    "No need to set aside a test set, as we need to first implement a working softmax model and then run a learning curve function on the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7453e813-60a0-4811-8585-b7bf082aab47",
   "metadata": {},
   "source": [
    "# Softmax Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe34c88b-8c54-4767-9349-7a209a4d2505",
   "metadata": {},
   "source": [
    "We need to do the following:\n",
    "- Random initialization of n+1 weights and k times where k=3 the number of classes (3 flower types)\n",
    "    - Each weight should be a vector that has 5 values and we should have 3 vectors\n",
    "- Compute softmax score for each class k\n",
    "- Compute probability score for each softmax score\n",
    "- Compute cross entropy gradient vector for each class k (should be same vector as weights - n+1 by 1 vector)\n",
    "- Combine all of the above into a Batch Gradient Descent Step function\n",
    "    - Args: initial 3 weight vectors, training data (m by n), label data (m by 1), learning rate\n",
    "    - Append a vector of 1s to training data (m by n+1)\n",
    "    - calculate softmax scores for each class\n",
    "    - calculate probability scores for each class\n",
    "    - calculate gradient vector for each class\n",
    "    - subtract learning rate x gradient vector from initial weights\n",
    "    - return the 3 new weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae056426-bf55-46bc-a108-46b13f915d5d",
   "metadata": {},
   "source": [
    "## Weight Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "770c922b-7ab0-4afc-a05c-9c3b54489979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.47644867, -1.15820463,  0.99975192,  0.46776206, -0.48977563],\n",
       "       [ 1.1661659 ,  1.20399017, -1.11875637,  1.36848649,  0.58877015],\n",
       "       [ 1.12410547, -1.82449253, -0.46877284,  0.08343482,  1.49358173]])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def random_init(classes):\n",
    "    init_thetas = []\n",
    "    for i in range(0,classes):\n",
    "        init_thetas.append(np.random.randn(5))\n",
    "    return np.array(init_thetas)\n",
    "    \n",
    "init_thetas = random_init(classes)\n",
    "init_thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "53b5c589-c9e7-4610-a55b-899aef69e906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 5)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_thetas.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7053037d-1b29-4143-b201-7ccacfc34ebc",
   "metadata": {},
   "source": [
    "We have a list of random 5 by 1 vector weights and one for each of the three flower classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289589d3-8ae0-41ad-8889-8d219b28fbba",
   "metadata": {},
   "source": [
    "## Softmax Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9a7f8c-7232-4110-8e54-460e445d940c",
   "metadata": {},
   "source": [
    "We need a function that, given one instance of X: x, calculates the softmax score of each class using the initial weights.\n",
    "- calculate softmax score for one instance\n",
    "- do it for each array in thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d2eaca6c-67dc-46ca-858f-61cb792e9422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1. , 5.1, 3.5, 1.4, 0.2])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_x = X[0]\n",
    "example_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3775fbf-bcb0-4998-b6ab-3bff5ab4a264",
   "metadata": {},
   "source": [
    "Let's use this instance to test our math functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7cb3ce51-07cd-4149-940b-cdb8ead61126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_k(x, theta_k):\n",
    "    sm_score = theta_k.T.dot(x)\n",
    "    return sm_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a32ed7fd-e4f6-47ea-925a-a7f9af21ad4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.7671119089056218"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_sm_k = softmax_k(example_x, init_thetas[0])\n",
    "example_sm_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9d8bd0-dfa0-4a85-a243-12d2deb62aa1",
   "metadata": {},
   "source": [
    "Note that it is automatically a numpy array of one, instead of just a float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "70dc8d4c-73e4-4826-bef6-924bfa38a4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_scores(x, thetas):\n",
    "    sm_scores = []\n",
    "    for theta in thetas:\n",
    "        sm_scores.append(softmax_k(x, theta))\n",
    "    return np.array(sm_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9779a8de-d813-43c3-815e-bf0c601b0653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -3.76711191,   1.43464903, -10.94172301])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_sm_scores = softmax_scores(example_x, init_thetas)\n",
    "example_sm_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dd846a-cc73-403d-b5d4-49c807f6d0b5",
   "metadata": {},
   "source": [
    "## Probability Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3061f2a6-45e1-43c9-9a07-a645ea981fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_k(sm_k, sm_scores):\n",
    "    return np.exp(sm_k) / np.sum(np.exp(sm_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9b09b6c1-86c7-4c84-8aeb-e7da59ce55bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005476676260672716"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_prob_k = prob_k(example_sm_k, example_sm_scores)\n",
    "example_prob_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6fe98444-5140-4a3d-aa79-f92370c1cc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_scores(sm_scores):\n",
    "    prob_scores = []\n",
    "    for sm_k in sm_scores:\n",
    "        prob_scores.append(prob_k(sm_k, sm_scores))\n",
    "    return np.array(prob_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2d5e9817-ff03-42f5-866e-a7c2020cb961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.47667626e-03, 9.94519130e-01, 4.19394816e-06])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_prob_scores = prob_scores(example_sm_scores)\n",
    "example_prob_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18edffd0-880e-4aa4-8da8-5eab72d2dcd9",
   "metadata": {},
   "source": [
    "This should be accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ca761ab6-dfec-4746-974a-1d079fdb7af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(example_prob_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdb6225-14a3-42fc-9388-2660a80a13b3",
   "metadata": {},
   "source": [
    "This makes sense, since the total probability should always be 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eff1847-b362-4aa9-86ba-64c0d56af79d",
   "metadata": {},
   "source": [
    "## Gradient Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8e475ff5-9b06-44ef-9dd2-433ba1469981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_grad(X, y, thetas):\n",
    "    # compute all softmax scores for all instances for all classes \n",
    "    # m by k (150 by 3)\n",
    "    sm = []\n",
    "    for x in X:\n",
    "        sm.append(softmax_scores(x, thetas))\n",
    "    sm = np.array(sm)\n",
    "    # indeed a (150, 3) numpy array\n",
    "        \n",
    "    # compute all prob scores for all instances for all classes\n",
    "    # should also be (150 by 3)\n",
    "    pb = []\n",
    "    for scores in sm:\n",
    "        pb.append(prob_scores(scores))\n",
    "    pb = np.array(pb)\n",
    "    # indeed (150, 3) and sum across columns produces a (150,) array of 1s\n",
    "    \n",
    "    # compute gradient vector for first class or y=0\n",
    "    grad_vec = []\n",
    "    for k in range(thetas.shape[0]):\n",
    "        errs = []\n",
    "        for i in range(X.shape[0]):\n",
    "            err = (pb[i, k] - (y[i] == k))\n",
    "            # err * X[i] is a (1, 5) or 1 by n+1 row vector\n",
    "            errs.append(err * X[i])\n",
    "        # errs is a (150, 5) matrix of errors for each feature value for each instance\n",
    "        grad_k = np.mean(errs, axis=0)\n",
    "        grad_vec.append(grad_k)\n",
    "    return np.array(grad_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "68840dd6-b058-44a0-b7d2-30046819c524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.33118776, -1.65813918, -1.13551034, -0.4840576 , -0.08140887],\n",
       "       [ 0.66451877,  3.85412818,  2.12683645,  2.33472103,  0.75674166],\n",
       "       [-0.33333101, -2.195989  , -0.99132611, -1.85066343, -0.67533279]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_grad(X, y, init_thetas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3a94a2-39f6-41c3-a8b5-9c60306d658f",
   "metadata": {},
   "source": [
    "So we got our gradient vector. Now we just need to iterate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67bc459-b64f-42ed-b076-8749a758d5df",
   "metadata": {},
   "source": [
    "## Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6cca11f5-1baf-4d31-8047-8a223513cdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single(x, thetas):\n",
    "    sm = softmax_scores(x, thetas)\n",
    "    pb = prob_scores(sm)\n",
    "    return np.argmax(pb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f09e655a-4030-4150-897c-424e89aa4d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_single(X[0], init_thetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "95694c0a-e581-4f6c-a98f-5a10678d36ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57ca7e4-c8e5-458d-8592-48e00efd0e5a",
   "metadata": {},
   "source": [
    "So we got it wrong, but this is expected - let's write predict for arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "1360f21c-ad39-4438-a81e-8855c7d4523d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_aux(X, thetas):\n",
    "    predictions = []\n",
    "    for x in X:\n",
    "        predictions.append(predict_single(x, thetas))\n",
    "    return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "1cf83ab9-f40d-435c-9a1a-4beb36e1685a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_aux(X, init_thetas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259746d2-3b5f-4452-9985-173db0deb46c",
   "metadata": {},
   "source": [
    "This is obviously wrong, but let's see if it will be more accurate after we train our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c23c008-af90-4560-8514-49aea88d517a",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a518ef57-3168-4707-8687-9ff23724529d",
   "metadata": {},
   "source": [
    "## Step Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236b172c-a2e1-40f4-819a-752aa0686b52",
   "metadata": {},
   "source": [
    "We need our function to iteratively improve and minimize cost.\n",
    "- Calculate gradient vectors\n",
    "- Subtract by a constant learning rate x gradient vector for each classes' theta\n",
    "- Do this epoch times and then return final thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "dedb2532-aba3-4187-97f0-87faa733d6ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.48310779, -0.74911548, -0.09355695, -0.74296951, -0.31062059],\n",
       "       [ 0.73858013,  0.58813831, -0.62268093, -0.06733114, -0.14894813],\n",
       "       [ 0.60105558, -0.40502176, -1.89907845, -2.03860217,  0.1182498 ]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "6bd7902f-8798-4ff6-a225-f4d4fd74af12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_step(X, y, init_thetas, l_rate, epochs):\n",
    "    thetas = init_thetas.copy()\n",
    "    for e in range(epochs):\n",
    "        # thetas is a list of k arrays and each array is a 5 by 1 array\n",
    "        grad_vecs = batch_grad(X, y, thetas)\n",
    "        # (3, 5) - l_rate * (3, 5)\n",
    "        thetas = thetas - (l_rate * grad_vecs)\n",
    "    return thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "8d332e40-94e7-4ba1-a380-072dd28b0654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.51961083, -0.69133747,  0.08670604, -1.05299478, -0.45339878],\n",
       "       [ 0.59884774, -0.27782354, -1.1129471 , -0.63705921, -0.36053198],\n",
       "       [ 0.70428494,  0.40316208, -1.58907526, -1.15884882,  0.47261183]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thetas_10e = batch_step(X, y, init_thetas, 0.1, 10)\n",
    "thetas_10e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "d368f302-a15c-436d-8b89-a63a18dd774f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.87843081,  0.1345169 ,  1.7355029 , -3.42539106, -1.56533779],\n",
       "       [ 1.29785131,  0.68355838, -1.19022508, -1.08241329, -1.45042904],\n",
       "       [-0.35353861, -1.3840742 , -3.16059414,  1.65890153,  2.67444791]])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thetas_1000e = batch_step(X, y, init_thetas, 0.1, 1000)\n",
    "thetas_1000e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f32ae49-4725-4aba-9682-ce54ec87db05",
   "metadata": {},
   "source": [
    "## Test New Thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "e4cfa598-ce27-40fe-b09f-eda37892f50d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_aux(X, thetas_10e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "8988b7c8-8c4d-4e4b-abdf-919e6a3ddfc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_1000e = predict_aux(X, thetas_1000e)\n",
    "predictions_1000e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "5b047a18-9707-44ab-a410-af569bfa49ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9733333333333334"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(predictions_1000e, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d8a5f8-6a9a-4d7b-b5c2-7dbd00d84491",
   "metadata": {},
   "source": [
    "Wow that's pretty good!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6966f9-8b25-4d1a-af82-e0639c68da6b",
   "metadata": {},
   "source": [
    "# Make Softmax Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6476fd35-8ff3-4543-b82a-9b40333b6a2e",
   "metadata": {},
   "source": [
    "Our next step is to include the training process in a class that we can fit and transform using sklearn.\n",
    "- create class framework\n",
    "- private variable and argument max_iter_ that records number of iterations per transform \n",
    "- private variable thetas_ that tracks the newest weights\n",
    "- use batch_step in transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "daa838c9-a457-42d4-8b7b-b85e44118901",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "class SoftmaxClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    def __init__(self, max_iter=10, l_rate=0.05):\n",
    "        self.max_iter = max_iter\n",
    "        self.l_rate = l_rate\n",
    "        \n",
    "        # init theta\n",
    "        self.thetas_ = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        # Check that X and y have correct shape\n",
    "        X, y = check_X_y(X, y)\n",
    "        \n",
    "        # Store the classes seen during fit\n",
    "        self.classes_ = unique_labels(y)\n",
    "        \n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "        \n",
    "        # initialize weights\n",
    "        if self.thetas_ is None:\n",
    "            self.thetas_ = random_init(len(self.classes_))\n",
    "        \n",
    "        # train weights and update theta\n",
    "        self.thetas_ = batch_step(self.X_, self.y_, self.thetas_, self.l_rate, self.max_iter)\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def predict(self, X):\n",
    "        # Check if fit has been called\n",
    "        check_is_fitted(self)\n",
    "        \n",
    "        # Input validation\n",
    "        X = check_array(X)\n",
    "        \n",
    "        return predict_aux(X, self.thetas_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "99f86366-d3a2-4cca-8b4f-0dac845d9398",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_clf = SoftmaxClassifier(max_iter=1000, l_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "7604658e-c272-4a8c-bef7-0f904dfc25e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SoftmaxClassifier(l_rate=0.1, max_iter=1000)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "f547b8c6-de65-46ec-873e-0295c125665c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = sm_clf.predict(X)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "392e3260-1f08-4aa2-a15f-80c7ce632b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(predictions, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287b0a9a-4347-430e-a3e9-2c68a27105dd",
   "metadata": {},
   "source": [
    "# Implement Early Stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21a9a08-f644-48e2-8880-de8587e8a6b0",
   "metadata": {},
   "source": [
    "Now we need to implement early stopping.\n",
    "- Split X, y into training and validation sets\n",
    "- Loop for a number of epochs and in each loop:\n",
    "    - fit model on training set\n",
    "    - predict on validation set\n",
    "    - get MSE of predictions\n",
    "    - compare MSE to current min MSE\n",
    "        - if less then update MSE, best_epoch, and best_model (with deepcopy)\n",
    "        - else keep a counter of how many times it has not beat current min MSE\n",
    "            - if counter exceeds a certain count (stop_count) then exit loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "b025055d-2183-4d82-bee3-f806f86bf96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from copy import deepcopy\n",
    "\n",
    "# 1 iteration epoch\n",
    "sm_clf = SoftmaxClassifier(max_iter=1, l_rate=0.1)\n",
    "\n",
    "# after how many non-improving iterations to stop\n",
    "max_stop_count = 1000\n",
    "current_stop_count = 0\n",
    "\n",
    "min_MSE = float(\"inf\")\n",
    "best_epoch = None\n",
    "best_model = None\n",
    "\n",
    "# split into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "for epoch in range(10000):\n",
    "    if current_stop_count >= max_stop_count:\n",
    "        break\n",
    "    sm_clf.fit(X_train, y_train)\n",
    "    predictions = sm_clf.predict(X_val)\n",
    "    MSE = mean_squared_error(predictions, y_val)\n",
    "    if MSE < min_MSE:\n",
    "        min_MSE = MSE\n",
    "        best_epoch = epoch\n",
    "        best_model = deepcopy(sm_clf)\n",
    "    else:\n",
    "        current_stop_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "8c7ae09a-3324-46da-a785-34cb4947d545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "0cf33a68-dabe-4681-97ac-d07e48fc01c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9733333333333334"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_predictions = best_model.predict(X)\n",
    "accuracy_score(final_predictions, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f06b39-e2d8-4e79-87c1-4ef618b01727",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd58ff53-b9c2-4530-ba4d-2e23787ae90d",
   "metadata": {},
   "source": [
    "So Softmax is a multiclass regression method that uses gradient descent.\n",
    "\n",
    "It calculate softmax scores for each instance for each class. \n",
    "Then it calculates the probability scores using those softmax scores.\n",
    "Finally, it uses the probability scores and the label to calculate error.\n",
    "\n",
    "Using this method and cross-entropy - a gradient vector for each class is calculated.\n",
    "Subtract this gradient vector from the previous weights to get new weights.\n",
    "\n",
    "Iterate to improve the model.\n",
    "\n",
    "Early stopping is also quite easy - iterate until model stops improving for some amount of time.\n",
    "\n",
    "I believe early stopping would have better results if our dataset was in the thousands or tens of thousands, sadly the iris dataset is only 150 instances."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
