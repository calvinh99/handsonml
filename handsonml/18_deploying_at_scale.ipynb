{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc562a4a-c2dc-4e99-b30a-54d293da1f6b",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dbf576b7-de05-40ea-a79c-ea01b2068ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# math and data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# time\n",
    "import time\n",
    "\n",
    "# functools\n",
    "from functools import partial\n",
    "\n",
    "# visualization and plotting\n",
    "from IPython import display\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# to plot nice figures\n",
    "%matplotlib inline\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# smooth animations\n",
    "import matplotlib.animation as animation\n",
    "mpl.rc('animation', html='jshtml')\n",
    "\n",
    "# handle files\n",
    "import os\n",
    "import sys\n",
    "import joblib\n",
    "\n",
    "# hash table classes\n",
    "from collections import Counter\n",
    "\n",
    "# output\n",
    "from tqdm.notebook import tqdm\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "# deep learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# reinforcement learning\n",
    "import gym"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6eb34f5-7341-47ce-b0cf-117f2ef2912f",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2d94d40b-cf12-428f-aee4-21dba202997b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./_tf_saved_models/18_deploy/my_mnist_model/0001\n"
     ]
    }
   ],
   "source": [
    "MODEL_DIR = os.path.join(\".\", \"_tf_saved_models\", \"18_deploy\")\n",
    "\n",
    "model_version = \"0001\"\n",
    "model_name = \"my_mnist_model\"\n",
    "model_path = os.path.join(MODEL_DIR, model_name, model_version)\n",
    "\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a6c87f-98d4-4424-b5ec-a4d79ebea4f3",
   "metadata": {},
   "source": [
    "# Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f75a05e-cbcb-405b-9788-68c0f8ff60e0",
   "metadata": {},
   "source": [
    "Let's learn how to train and deploy models at scale (following chapter 19 of handsonml)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfb84f4-0d1f-43cb-ac4c-5d05a3f6e268",
   "metadata": {},
   "source": [
    "## TF Serving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d223f9-54bb-4d81-a923-7a41e44a9e33",
   "metadata": {},
   "source": [
    "Let's learn to use TF Serving to deploy our models as a queryable microservice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa98c83-4199-47fe-93bc-1ae62a6d476f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a770559d-9b03-45c8-9245-5e882002fa53",
   "metadata": {},
   "source": [
    "Let's train a quick mnist model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4386075-5018-4da4-8507-0be4cd91693f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_raw, valid_set_raw, test_set_raw = tfds.load(\"mnist\", as_supervised=True, \n",
    "                                                       split=[\"train\", \"test[:50%]\", \"test[50%:]\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d93558c5-5362-4f51-a19a-4195a5efb23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_crop(X):\n",
    "    \"\"\"\n",
    "    Randomly crops a given image\n",
    "    \"\"\"\n",
    "    shape = tf.shape(X)\n",
    "    dims_factor = tf.random.uniform([], 0.9, 1.0, dtype=tf.float32)\n",
    "    height_dim  = tf.multiply(dims_factor, tf.cast(shape[0], tf.float32))\n",
    "    width_dim   = tf.multiply(dims_factor, tf.cast(shape[1], tf.float32))\n",
    "    X_cropped = tf.image.random_crop(X, [height_dim, width_dim, 1])\n",
    "    X_final = tf.image.resize(X_cropped, shape[:2])\n",
    "    return X_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e1582b5d-8880-422c-aaee-1f87f71ce144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(X_batch, y_batch, augment=False):\n",
    "    X_batch = tf.cast(X_batch, tf.float32) / 255.\n",
    "    if augment:\n",
    "        X_batch = tf.map_fn(random_crop, X_batch)\n",
    "    return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "f8269a60-750c-4b78-bdab-e78a38ab7bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_set = train_set_raw.shuffle(60000).batch(batch_size).map(partial(preprocess, augment=True)).prefetch(1)\n",
    "valid_set = valid_set_raw.batch(batch_size).map(preprocess).prefetch(1)\n",
    "test_set = test_set_raw.batch(batch_size).map(preprocess).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "28b09e3c-b818-4b55-91a2-cd80d3f95efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_digits(X_batch):\n",
    "    shape = tf.shape(X_batch)\n",
    "    n_digits = shape[0]\n",
    "    n_rows = 6\n",
    "    n_cols = 6\n",
    "    plt.figure(figsize=(2 * n_rows, 2 * n_cols))\n",
    "    for index in range(n_digits):\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(X_batch[index], cmap=\"binary\")\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9dbf396c-bd12-4ba5-9fa6-dc7b947409f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=[28, 28, 1]),\n",
    "    keras.layers.Conv2D(filters=16, kernel_size=5, strides=2, \n",
    "                        padding=\"same\", activation=\"relu\"),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "92886e50-6ba9-4fca-96c3-55717713f2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Nadam(learning_rate=5e-6)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "718a1e9a-a5b0-4a23-b7f4-b2ad7670e6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0067 - accuracy: 0.9990 - val_loss: 0.0310 - val_accuracy: 0.9892\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcc6c433be0>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_set, epochs=1,\n",
    "          validation_data=valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "351ae8c3-3ad0-43fb-94c7-4097bd69de5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0274 - accuracy: 0.9902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.02744220197200775, 0.9901999831199646]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63286ed-4773-49b8-a40d-bcfd6a652cbf",
   "metadata": {},
   "source": [
    "### Export SavedModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1baab50d-0d3d-40ae-b7a9-bb59aed15a2e",
   "metadata": {},
   "source": [
    "Now that we've trained a mnist model with 99% accuracy on test set, let's export it to the `SavedModel` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "089792b1-6222-4a36-b621-7604d2a6edd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./_tf_saved_models/18_deploy/my_mnist_model/0001/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./_tf_saved_models/18_deploy/my_mnist_model/0001/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2c19f2-5169-4747-b0b5-32c17baa5e09",
   "metadata": {},
   "source": [
    "Run the below docker command to create a docker container using the tensorflow/serving image and binding our model directory to the mountpoint used by the container."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ede4ca-ec9b-4c61-8772-28838e30a4ce",
   "metadata": {},
   "source": [
    "`docker run -it --rm -p 8500:8500 -p 8501:8501 \\\n",
    "-v \"$HOME/ml/handsonml/_tf_saved_models/18_deploy/my_mnist_model:/models/my_mnist_model\" \\\n",
    "-e MODEL_NAME=my_mnist_model \\\n",
    "tensorflow/serving`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826b2e8e-2b78-4d27-b1a9-b462ab1c2c19",
   "metadata": {},
   "source": [
    "### Query TF Serving via Rest API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268ce82b-4354-4f75-827b-55daf9766f14",
   "metadata": {},
   "source": [
    "Let's create our json used to query the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0e5572d5-f587-4011-8c53-c63a9ebcee28",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new, y_new = next(iter(test_set.take(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "c09f990c-8f36-4f79-98b8-bed1c3e8e953",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_new.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75de3df2-c6ed-463b-bd55-1f93b20cf8ea",
   "metadata": {},
   "source": [
    "Create json string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a692a28f-1695-48c2-9f42-1506031e9293",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "input_data_json = json.dumps({\n",
    "    \"signature_name\": \"serving_default\",\n",
    "    \"instances\": X_new.tolist(),\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd72380-7cfa-4adf-ae6f-377816f4406c",
   "metadata": {},
   "source": [
    "The json string is very long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "7648b142-b857-4223-b278-5a38437f4326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"signature_name\": \"serving_default\", \"instances\": [[[[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0 \n",
      "\n",
      "...\n",
      "\n",
      " [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]]]}\n"
     ]
    }
   ],
   "source": [
    "print(input_data_json[:100], \"\\n\\n...\\n\\n\", input_data_json[-100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9e44bf55-3250-4349-b430-7080d2a875c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(str, 248981)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(input_data_json), len(input_data_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a557595c-dd8c-48c6-8f63-e6e4575dfa4c",
   "metadata": {},
   "source": [
    "Now let's send an HTTP POST request to our container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "1d33b149-b687-4dd6-b0b9-7fad23d622a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "SERVER_URL = \"http://localhost:8501/v1/models/my_mnist_model:predict\"\n",
    "response = requests.post(SERVER_URL, data=input_data_json)\n",
    "response.raise_for_status() # raise exception if error\n",
    "response_json = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "530332b8-51d8-4f57-bcc9-0a0c29a2092f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 10)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_probas = np.array(response_json[\"predictions\"])\n",
    "y_probas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a19d7ab8-8dc1-4f35-8117-cafa8d8bb5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(y_probas, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c99974f7-1977-4d0b-a220-70ebb95cae4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32,), dtype=bool, numpy=\n",
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True])>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred == y_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cedde1-066b-4a8f-ad09-b425b2466bd6",
   "metadata": {},
   "source": [
    "Nice!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43dfde1-773f-46bf-a3d8-db8bcbd49cdd",
   "metadata": {},
   "source": [
    "### Query TF Serving via gRPC API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9f6599-ce55-4e88-b532-9324d58b9f2f",
   "metadata": {},
   "source": [
    "REST API converts numpy to string json format and back, so for transferring large numpy arrays there would be high latency and bandwidth usage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0cc83d-5925-44e5-9a91-f7a35c538146",
   "metadata": {},
   "source": [
    "Use gRPC which sends and receives protobufs (serialized binary format to efficiently send or store lots of data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c649d366-92ae-4787-b1bb-22c19651f887",
   "metadata": {},
   "source": [
    "Let's use the `tensorflow-serving-api` library to create these protobufs for request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "26d31c09-1806-4775-9525-1109eedc08cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_serving.apis.predict_pb2 import PredictRequest\n",
    "\n",
    "request = PredictRequest()\n",
    "request.model_spec.name = model_name\n",
    "request.model_spec.signature_name = \"serving_default\"\n",
    "input_name = model.input_names[0] # guessing this is the name of the model's input layer\n",
    "\n",
    "request.inputs[input_name].CopyFrom(tf.make_tensor_proto(X_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f741c2ad-8246-448c-86e5-7e4591714eaa",
   "metadata": {},
   "source": [
    "Now let's send this `PredictRequest` object to the server and get its response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d48c5b06-27b8-4c65-9a6e-a2da30a3f47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import grpc\n",
    "from tensorflow_serving.apis import prediction_service_pb2_grpc\n",
    "\n",
    "channel = grpc.insecure_channel(\"localhost:8500\")\n",
    "predict_service = prediction_service_pb2_grpc.PredictionServiceStub(channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4235d46-50c1-4278-a253-d466538755ae",
   "metadata": {},
   "source": [
    "Use the service to send request and get a `PredictResponse` object back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "6399e679-881c-4db0-aa55-8ad0c2e98b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = predict_service.Predict(request, timeout=10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729e79d2-3bb1-4856-ae0a-23bd11e6f2f0",
   "metadata": {},
   "source": [
    "Convert response to tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "bc738e97-7816-4e24-ac2d-091cb7628d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_name = model.output_names[0] # name of output layer\n",
    "output_proto = response.outputs[output_name] # tensorflow.core.framework.tensor_pb2.TensorProto\n",
    "y_probas = tf.make_ndarray(output_proto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "f34d23a2-dbf2-4dc2-b6e4-e163052fe0f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32,), dtype=bool, numpy=\n",
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True])>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_probas, axis=1) == y_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683ecf9a-25a1-4984-bbb1-e55f4e217d35",
   "metadata": {},
   "source": [
    "### Deploying New Model Version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12acaf05-175b-45d0-9119-7e0533dad39e",
   "metadata": {},
   "source": [
    "Let's create a new version of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "066c0dcf-8e8f-48f5-a029-98136114c8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=[28, 28, 1]),\n",
    "    keras.layers.Conv2D(filters=32, kernel_size=5,\n",
    "                        padding=\"same\", activation=\"elu\"),\n",
    "    keras.layers.MaxPooling2D(),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=3,\n",
    "                        padding=\"same\", activation=\"elu\"),\n",
    "    keras.layers.MaxPooling2D(),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(512, activation=\"selu\"),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    keras.layers.Dense(128, activation=\"selu\"),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c458de-4476-4e9f-8155-c97fc62e160a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Nadam(learning_rate=5e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "lr_plateau_cb = keras.callbacks.ReduceLROnPlateau(factor=0.25, patience=2)\n",
    "\n",
    "model.fit(train_set, epochs=10,\n",
    "          validation_data=valid_set,\n",
    "          callbacks=[lr_plateau_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "ed55faf8-92ef-4610-b272-1e2707f92d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 7ms/step - loss: 0.0254 - accuracy: 0.9934\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.02542022615671158, 0.993399977684021]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea951a56-3677-44fb-9d39-41bd696635c8",
   "metadata": {},
   "source": [
    "Saving the second version of the model with a 99.3% accuracy on test set - using a deeper CNN with MaxPooling2D and deeper FC layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "4a17baf9-2bf4-4e55-b7ec-fa75f31f14b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./_tf_saved_models/18_deploy/my_mnist_model/0002'"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_version = \"0002\"\n",
    "model_name = \"my_mnist_model\"\n",
    "model_path = os.path.join(MODEL_DIR, model_name, model_version)\n",
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "c3c56324-724e-46e0-a873-e17303966053",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./_tf_saved_models/18_deploy/my_mnist_model/0002/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./_tf_saved_models/18_deploy/my_mnist_model/0002/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40792449-9db6-4ce0-b498-fe84fe71a723",
   "metadata": {},
   "source": [
    "### Deploy to GCP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4de771c-94d5-40ae-a16e-8ef64f2fd023",
   "metadata": {},
   "source": [
    "- Create project\n",
    "- Enable billing\n",
    "- Create bucket on GCS\n",
    "    - Upload model file to bucket\n",
    "- Create model on AI Platform\n",
    "    - Create version for model\n",
    "- Create service account for project\n",
    "    - Give AI Platform developer permissions\n",
    "    - Create and download JSON key\n",
    "\n",
    "Now we can query our model using the service account!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "b2795508-86f9-4417-adb7-04f4e606d8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install google-api-python-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "113d2875-f5b3-42b0-a865-96e63e1ad0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = os.path.join(\".\", \"gcp_service_keys\", \n",
    "                                                            \"deploy_first_model_service_account_key.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d9da2f-ddb9-4ff7-8c3d-0cb2987723df",
   "metadata": {},
   "source": [
    "Now let's create a resource object that wraps access to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "5ace49c4-4f08-4c5f-8ec3-43e70f4879d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/deploy-first-model/models/my_mnist_model/versions/v0001'"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import googleapiclient.discovery\n",
    "\n",
    "project_id = \"deploy-first-model\"\n",
    "model_id = \"my_mnist_model\"\n",
    "version_id = \"v0001\"\n",
    "model_path = os.path.join(\"projects\", project_id, \n",
    "                          \"models\", model_id,\n",
    "                          \"versions\", version_id)\n",
    "model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da26a8f4-3062-40d8-95d8-b36a08f5c0c7",
   "metadata": {},
   "source": [
    "You will get below error if you did not set `GOOGLE_APPLICATION_CREDENTIALS` environment variable.\n",
    ">DefaultCredentialsError: Could not automatically determine credentials. Please set GOOGLE_APPLICATION_CREDENTIALS or explicitly create credentials and re-run the application. For more information, please see https://cloud.google.com/docs/authentication/getting-started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "badfd0da-eab5-4871-a83c-9641dab3f3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_resource = googleapiclient.discovery.build(serviceName=\"ml\", version=\"v1\").projects()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602a1f29-814a-4461-9b81-a2c677620d2d",
   "metadata": {},
   "source": [
    "Now let's actually implement using the resource object to call the prediction service and get predictions back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "153be819-40a2-4254-9cda-313eee28581c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_name = 'dense_9' # from metagraph serving_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "4f07fa83-a980-4857-9a2b-b935a51aad31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_gcp(X):\n",
    "    \"\"\" \n",
    "    X has to be a numpy with shape (batch_size, 28, 28, 1) \n",
    "    and scaled from 0 to 1 with dtype float32. \n",
    "    \"\"\"\n",
    "    \n",
    "    input_data_json = {\"signature_name\": \"serving_default\",\n",
    "                       \"instances\": X.tolist()}\n",
    "    request = ml_resource.predict(name=model_path, body=input_data_json)\n",
    "    response = request.execute()\n",
    "    if \"error\" in response:\n",
    "        raise RuntimeError(response[\"error\"])\n",
    "    return np.array([pred[output_name] for pred in response[\"predictions\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "1487145c-3f62-4f41-9ef4-221c13f3829f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probas = predict_from_gcp(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "fe9e42ba-6a13-46a2-b439-19e29007d9e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32,), dtype=bool, numpy=\n",
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True])>"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_probas, axis=1) == y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648bafd4-ed65-4d3b-8ead-bb3ffdc16227",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
