{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "116a94dc-835b-4c80-ac45-ead7bc26c6ac",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f12d96c8-d100-47b0-ba04-366ff1fdb9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle math and data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# to plot nice figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# handle files\n",
    "import os\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01630ecb-576d-4046-8bca-561e768d76a2",
   "metadata": {},
   "source": [
    "# Get Moon Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c254053-7d4f-4a92-ae6f-4303a1c11ec1",
   "metadata": {},
   "source": [
    "We will first generate 10,000 instances of moon dataset using sklearn's `make_moons` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "ced9f0f5-ec08-413d-9c74-d0c9fd69aa11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 2), (10000,))"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(n_samples=10000, noise=0.4, random_state=42)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "93856c79-5639-4360-91fc-019e85c6c680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.9402914 ,  0.12230559],\n",
       "        [ 0.12454026, -0.42477546],\n",
       "        [ 0.26198823,  0.50841438]]),\n",
       " array([1, 0, 0]))"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:3], y[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a98e7152-0f95-4677-9a19-c5df57331b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f54624-0e00-4329-a449-6229577eb33d",
   "metadata": {},
   "source": [
    "Ok we can see that there are two features and the labels are 0s and 1s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe43d4b2-8cd0-428c-adc9-b410157d8e2c",
   "metadata": {},
   "source": [
    "## Split Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "10d97318-5a40-45dd-bc93-dffb9b26376f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 2), (8000,))"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66caf26a-e29a-4bc7-9776-1e197ba514f5",
   "metadata": {},
   "source": [
    "Nice, now let's set aside the test set and use our 8000 instances in the train set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d115d7-059f-4ed2-9c4e-9c6975ea2a74",
   "metadata": {},
   "source": [
    "# Fine-Tune D-Tree Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e7439f-d030-45b8-b99e-47a7553def76",
   "metadata": {},
   "source": [
    "We don't need to do model selection since we are only going to use decision-tree. We can jump straight to fine-tuning with `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "8b7a6e37-91ab-4cb1-b3bc-7b2d69d9f6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 98 candidates, totalling 294 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=DecisionTreeClassifier(random_state=42),\n",
       "             param_grid={'max_leaf_nodes': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
       "                                            13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
       "                                            22, 23, 24, 25, 26, 27, 28, 29, 30,\n",
       "                                            31, ...]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# using our hint\n",
    "param_grid = {'max_leaf_nodes': list(range(2, 100))}\n",
    "\n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(random_state=42),\n",
    "                           param_grid, cv=3, verbose=1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c470cb9d-75f7-498b-87d2-9a4993ddcc06",
   "metadata": {},
   "source": [
    "Now let's check the best estimator we got."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "09ecaed8-97eb-4b88-8323-c09773371d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_leaf_nodes=17, random_state=42)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "050e6ef6-7a5e-4929-a950-496ba133868f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8555001986342105"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f88975e-88bf-483a-abff-b200d96ce175",
   "metadata": {},
   "source": [
    "The score is within our bounds! Now let's train our model and evaluate it on the test set!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68267a0-1ae8-4d2a-8e06-7a27b7dca42b",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "74282816-dada-4f2a-b803-bfe2d01b540c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_leaf_nodes=17, random_state=42)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree_clf = grid_search.best_estimator_\n",
    "\n",
    "dtree_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "298ef12f-7d12-402d-822b-4a3a2be7b821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8695"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(dtree_clf.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbc4efb-3f9b-412d-96f5-503009c7fa61",
   "metadata": {},
   "source": [
    "Great! This is within .85 and .87\n",
    "<br>\n",
    "Next, let's try creating our own Random Forest!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7e1f70-1756-437c-98d6-9a5ea8bbe980",
   "metadata": {},
   "source": [
    "# Creating a Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbeb5202-1fbc-4e72-ab28-fe071d2f86b1",
   "metadata": {},
   "source": [
    "Our plan is to train 1000 decision tree classifiers on 1000 smaller subsets of the training data. Then evaluate any new instances using all 1000 trees and returning the most common class amongst all 1000 predictions.\n",
    "<br><br>\n",
    "We will need to do the following:\n",
    "- Generate 1000 random datasets, each containing 100 instances\n",
    "- Train 1000 d-trees on each dataset using our hyperparameters from fine-tuning previously\n",
    "    - Evaluate the accuracy of each d-tree on the test set and average all 1000 accuracies (probably won't be very good)\n",
    "- Create a function that makes a prediction on an instance using all 1000 d-trees\n",
    "    - Gets all 1000 predictions using the d-trees\n",
    "    - Finds most common prediction and return it\n",
    "    - Create a function that can do the same for an array of instances\n",
    "- Evaluate our forest on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192eaca1-ae3e-4daa-9ece-718af1518105",
   "metadata": {},
   "source": [
    "## Generate 1000 Smaller Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "9f9307ab-c2ad-4a25-8be4-4c2e6d5ad6b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 2), (100,))"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "\n",
    "n_trees = 1000\n",
    "n_instances = 100\n",
    "s_split = ShuffleSplit(n_splits=n_trees, train_size=n_instances,\n",
    "                       random_state=42)\n",
    "\n",
    "mini_sets = []\n",
    "\n",
    "for mini_train_index, _ in s_split.split(X_train, y_train):\n",
    "    # ignore test_indices\n",
    "    X_mini_train = X_train[mini_train_index]\n",
    "    y_mini_train = y_train[mini_train_index]\n",
    "    \n",
    "    mini_sets.append((X_mini_train, y_mini_train))\n",
    "    \n",
    "mini_sets[0][0].shape, mini_sets[0][1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368a5f17-e08a-400b-92b1-8313bb787ba9",
   "metadata": {},
   "source": [
    "`mini_sets` is a list of 1000 tuples of (X, y) in the shapes above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2472aea-4868-497a-8ff0-24fa00ad5195",
   "metadata": {},
   "source": [
    "Ok now we have a list of 1000 datasets of size 100 for both X (input features) and y (target feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74a2e68-674e-4654-9bea-1387d2e2e9cf",
   "metadata": {},
   "source": [
    "## Train 1000 D-Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3965fd5-a105-4280-85df-631ca15166db",
   "metadata": {},
   "source": [
    "Now we need to iterate through the datasets and train a list of 1000 d-trees. Then evaluate their accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "ffd29b4c-dab6-4a7a-bcc4-12bcd5b2c3f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8054499999999999"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.base import clone\n",
    "\n",
    "# make sure to use [] because using () produces a generator object (aka it hasn't generated the list yet lmao)\n",
    "# I was getting 50% accuracy because the generator object was returning only 0s!\n",
    "forest = [clone(grid_search.best_estimator_) for _ in range(len(mini_sets))]\n",
    "\n",
    "accuracy_scores = []\n",
    "\n",
    "for tree, (X_mini_train, y_mini_train) in zip(forest, mini_sets):\n",
    "    tree.fit(X_mini_train, y_mini_train)\n",
    "    \n",
    "    y_pred = tree.predict(X_test)\n",
    "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "np.mean(accuracy_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c82e67-fd17-40ff-ae39-0d23f136e1e1",
   "metadata": {},
   "source": [
    "Produces only around 80% accuracy. Let's use the entire forest to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496a22ea-62eb-45ec-bead-7deef57e9c7d",
   "metadata": {},
   "source": [
    "## Predict Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "0a78c23c-7386-44c2-95fa-64778ee0dcbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import mode\n",
    "\n",
    "def forest_predict(forest, X):\n",
    "    Y_pred = np.empty([len(forest), len(X)], dtype=np.uint8)\n",
    "\n",
    "    for tree_index, tree in enumerate(forest):\n",
    "        Y_pred[tree_index] = tree.predict(X_test)\n",
    "    \n",
    "    return mode(Y_pred, axis=0)[0].reshape([-1])\n",
    "\n",
    "Y_pred = forest_predict(forest, X_test)\n",
    "Y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3578055-aafa-4d78-afac-a0a20129cd6a",
   "metadata": {},
   "source": [
    "Let's check the accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "ef3c657d-0da2-4fbd-b626-d6c4d5e3696b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.872"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_pred, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
